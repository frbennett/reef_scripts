{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir is: C:\\PythonScriptingForGBR\\reef_scripts\\ResultsAnalysis\n"
     ]
    }
   ],
   "source": [
    "##Robs summariser of RC9 Additional Scenario Regional Contributor tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import libarchive\n",
    "import tempfile\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "#mainPath = 'P:\\projects\\RC9_ResultsSets\\Tester'\n",
    "mainPath = r'\\\\athenasmb\\pdreef\\RC9_RC2017\\AdditionalScenarios\\Results\\ReportCardSpan_1986_2014'\n",
    "#mainPath = r'\\\\athenasmb\\pdreef\\RC9_RC2017\\RC9_ResultsSets_PointOfTruth'\n",
    "#outPath = 'P:\\projects\\RC9_ResultsSets\\RegContribTables'\n",
    "outPath = 'P:\\projects\\RC9_ResultsSets\\AdditionalScenarioSummaries'\n",
    "summariesOutFolder = 'SummariesWithProcess'\n",
    "baseFileName = 'ScenarioBaseline'\n",
    "D2CFileName = 'Scenario_DtoC'\n",
    "AllBFileName = 'Scenario_AllB'\n",
    "AllAFileName = 'Scenario_AllA'\n",
    "\n",
    "regContributorFileName = 'RegContributorDataGrid.csv'\n",
    "fuAreasFileName = 'fuAreasTable.csv'\n",
    "#outputCSVEnd = 'RegToOutlet_Alt.csv'\n",
    "outputCSVEnd = 'RegToOutlet.csv'\n",
    "baselineScenarioName = 'Baseline'\n",
    "changeScenarioName = 'Change'\n",
    "predevScenarioName = 'PreDev'\n",
    "reportCardString = 'RC2017'\n",
    "\n",
    "preDevCSVLoc = 'P:\\projects\\RC9_ResultsSets\\RegContribTables\\Summaries'\n",
    "\n",
    "theTempDir = tempfile.gettempdir()\n",
    "theCurrentDir = os.getcwd()\n",
    "\n",
    "print(\"Current dir is: \" + theCurrentDir)\n",
    "\n",
    "pathToContstitsToGrpFile = r'\\\\athenasmb\\pdreef\\RC9_RC2017\\RC9_ResultsSets_PointOfTruth\\constituentsToGroups.csv'\n",
    "\n",
    "annLoadToStream = 'AnnLoadToStreamKG'\n",
    "annLoadToExport = 'AnnLoadToExportKG'\n",
    "\n",
    "scenarioList = [baseFileName, D2CFileName, AllBFileName, AllAFileName]\n",
    "#regList = ['BM','CY','FI','MW','WT']\n",
    "regExtDict = {\n",
    "                'BM':'7z',\n",
    "               'BU':'zip',\n",
    "               'CY':'7z',\n",
    "               'FI':'7z',\n",
    "               'MW':'7z',\n",
    "               'WT':'7z'\n",
    "              }\n",
    "\n",
    "#scenarioToFolderDict = {baselineScenarioName:baseFolderEnd, changeScenarioName:changeFolderEnd, predevScenarioName:predevFolderEnd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathInfo(regionIDString, scenarioString):\n",
    "    #fileIn = mainPath + '\\\\' + regionIDString + '\\\\Model_Outputs\\\\' + regionIDString + '_' + scenarioToFolderDict[scenarioString] + '\\\\' + regContributorFileName\n",
    "    #fileOut = outPath + '\\\\' + summariesOutFolder + '\\\\' + regionIDString + '_' + reportCardString + '_' + scenarioString + '_' + outputCSVEnd\n",
    "    fileIn = mainPath + '\\\\' + regionIDString + '_RC9_' + scenarioString + '_1986_2014.' + regExtDict[regionIDString]\n",
    "    fileOut = outPath + '\\\\' + regionIDString + '_' + reportCardString + '_' + scenarioString + '_' + outputCSVEnd\n",
    "    return fileIn, fileOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build relationships of constituent names to groups\n",
    "#tssGrp = 'TSS'\n",
    "#tnGrp = 'TN'\n",
    "#tpGrp = 'TP'\n",
    "#ps2Grp = 'PSII'\n",
    "#nonps2Grp = 'non-PSII'\n",
    "##Nope, will read in a CSV to DataFrame instead, thus joing will 'drop' flow from this comparison\n",
    "#constToGrp = {'Sediment - Fine':tssGrp}\n",
    "\n",
    "constToGrp = pd.read_csv(pathToContstitsToGrpFile)\n",
    "\n",
    "baseSupplyStr = 'Base_Supply_KG'\n",
    "baseExportStr = 'Base_Export_KG'\n",
    "regbaseExportStr = 'Reg_Base_Export_KG'\n",
    "D2CSupplyStr = 'D2C_Supply_KG'\n",
    "D2CExportStr = 'D2C_Export_KG'\n",
    "regD2CExportStr = 'Reg_D2C_Export_KG'\n",
    "D2CPercRedStr = 'D2C_PercRed'\n",
    "AllBSupplyStr = 'AllB_Supply_KG'\n",
    "AllBExportStr = 'AllB_Export_KG'\n",
    "regAllBExportStr = 'Reg_AllB_Export_KG'\n",
    "AllBPercRedStr = 'AllB_PercRed'\n",
    "AllASupplyStr = 'AllA_Supply_KG'\n",
    "AllAExportStr = 'AllA_Export_KG'\n",
    "regAllAExportStr = 'Reg_AllA_Export_KG'\n",
    "AllAPercRedStr = 'AllA_PercRed'\n",
    "predevSupplyStr = 'PreDev_Supply_KG'\n",
    "predevExportStr = 'PreDev_Export_KG'\n",
    "regpredevExportStr = 'Reg_PreDev_Export_KG'\n",
    "\n",
    "D2CRedOnly = 'D2CREDONLYAMT'\n",
    "AllBRedOnly = 'AllBREDONLYAMT'\n",
    "AllARedOnly = 'AllAREDONLYAMT'\n",
    "\n",
    "D2CRedOnlyTotal = 'D2CREDONLYTOT'\n",
    "AllBRedOnlyTotal = 'AllBREDONLYTOT'\n",
    "AllARedOnlyTotal = 'AllAREDONLYTOT'\n",
    "\n",
    "D2CRedAttributed = 'D2CREDONLYATT'\n",
    "AllBRedAttributed = 'AllBREDONLYATT'\n",
    "AllARedAttributed = 'AllAREDONLYATT'\n",
    "\n",
    "\n",
    "repRegStr = 'Rep_Region'\n",
    "sourceRegStr = 'Source Region'\n",
    "constituentStr = 'Constituent'\n",
    "fuStr = 'FU'\n",
    "groupStr = 'GROUP'\n",
    "modelRegStr = 'MODELREG'\n",
    "#percRedStr = 'PercReduction'\n",
    "regTotalStr = 'REGIONAL TOTAL'\n",
    "processStr = 'Process'\n",
    "\n",
    "#allExportsAndReductions = pd.DataFrame(columns=[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr, baseExportStr, changeExportStr, percRedStr])\n",
    "#allExportsAndReductions = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathInfoForReductions(regionIDString, scenarioString):\n",
    "    fileIn = mainPath + '\\\\' + regionIDString + '_RC9_' + scenarioString + '_1986_2014.7z'\n",
    "    fileOut = outPath + '\\\\' + regionIDString + '_' + reportCardString + '_' + scenarioString + '_' + outputCSVEnd\n",
    "    return fileIn, fileOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreDevPathInfo(regionIDString, scenarioString):\n",
    "    fileIn = mainPath + '\\\\' + regionIDString + '_RC9_' + scenarioString + '_1986_2014.7z'\n",
    "    fileOut = preDevCSVLoc + '\\\\' + regionIDString + '_' + reportCardString + '_' + scenarioString + '_' + outputCSVEnd\n",
    "    return fileIn, fileOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now we would be reading in known summary files\n",
    "\n",
    "def calculateReductions(regName, thisRegID):\n",
    "    \n",
    "        \n",
    "    baseOutDir = outPath + '\\\\' + summariesOutFolder\n",
    "    if not os.path.exists(baseOutDir):\n",
    "        os.makedirs(baseOutDir)\n",
    "        print(\"Made dir: \" + baseOutDir)\n",
    "    \n",
    "    \n",
    "    unneededFile, theBaseSummaryFile = getPathInfoForReductions(thisRegID, baseFileName)\n",
    "    unneededFile, theD2CSummaryFile = getPathInfoForReductions(thisRegID, D2CFileName)\n",
    "    unneededFile, theAllBSummaryFile = getPathInfoForReductions(thisRegID, AllBFileName)\n",
    "    unneededFile, theAllASummaryFile = getPathInfoForReductions(thisRegID, AllAFileName)\n",
    "    unneededFile, thePreDevSummaryFile = getPreDevPathInfo(thisRegID, predevScenarioName)\n",
    "    \n",
    "    #print(\"Reading: \" + theBaseSummaryFile)\n",
    "    baseSummaryDF = pd.read_csv(theBaseSummaryFile)\n",
    "    #print(\"Reading: \" + theChangeSummaryFile)\n",
    "    D2CSummaryDF = pd.read_csv(theD2CSummaryFile)\n",
    "    AllBSummaryDF = pd.read_csv(theAllBSummaryFile)\n",
    "    AllASummaryDF = pd.read_csv(theAllASummaryFile)\n",
    "    #print(\"Reading: \" + thePreDevSummaryFile)\n",
    "    predevSummaryDF = pd.read_csv(thePreDevSummaryFile)\n",
    "    \n",
    "    #inner drops out those that don't merge, left keep them\n",
    "    baseTotals = pd.merge(baseSummaryDF.groupby([repRegStr,constituentStr,fuStr, processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum', 'AreaHA':'first'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT']).reset_index()\n",
    "    baseTotals = baseTotals.rename(columns={repRegStr:sourceRegStr,'AreaHA':'AREA_HA',annLoadToStream:baseSupplyStr, annLoadToExport:baseExportStr})\n",
    "    baseTotals = baseTotals[[sourceRegStr, groupStr, constituentStr, fuStr, processStr, 'AREA_HA', baseSupplyStr, baseExportStr]]\n",
    "    #baseTotals.head(40)\n",
    "    \n",
    "    predevTotals = pd.merge(predevSummaryDF.groupby([repRegStr,constituentStr,fuStr, processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT']).reset_index()\n",
    "    predevTotals = predevTotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:predevSupplyStr, annLoadToExport:predevExportStr})\n",
    "    predevTotals = predevTotals[[sourceRegStr, constituentStr, fuStr, processStr, predevSupplyStr, predevExportStr]]\n",
    "    \n",
    "    D2CTotals = pd.merge(D2CSummaryDF.groupby([repRegStr,constituentStr,fuStr, processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT'])\n",
    "    D2CTotals = D2CTotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:D2CSupplyStr, annLoadToExport:D2CExportStr})\n",
    "    D2CTotals = D2CTotals[[sourceRegStr, constituentStr, fuStr, processStr, D2CSupplyStr, D2CExportStr]]\n",
    "    \n",
    "    AllBTotals = pd.merge(AllBSummaryDF.groupby([repRegStr,constituentStr,fuStr, processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT'])\n",
    "    AllBTotals = AllBTotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:AllBSupplyStr, annLoadToExport:AllBExportStr})\n",
    "    AllBTotals = AllBTotals[[sourceRegStr, constituentStr, fuStr, processStr, AllBSupplyStr, AllBExportStr]]\n",
    "    \n",
    "    AllATotals = pd.merge(AllASummaryDF.groupby([repRegStr,constituentStr,fuStr, processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT'])\n",
    "    AllATotals = AllATotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:AllASupplyStr, annLoadToExport:AllAExportStr})\n",
    "    AllATotals = AllATotals[[sourceRegStr, constituentStr, fuStr, processStr, AllASupplyStr, AllAExportStr]]\n",
    "    \n",
    "    #changeTotals.head(8)\n",
    "    \n",
    "    reductTotalsDF = [D2CTotals, AllBTotals, AllATotals]\n",
    "    reductionsMerged = reduce(lambda  left,right: pd.merge(left,right,on=[sourceRegStr, constituentStr, fuStr, processStr],\n",
    "                                                           how='outer'), reductTotalsDF)\n",
    "    \n",
    "    #, columns=['Rep_Region', 'GROUP', 'Constituent', 'FU', 'AREA_HA', 'Base_Supply_KG', 'Base_Export_KG', 'PreDev_Supply_KG', 'PreDev_Export_KG', 'Change_Supply_KG', 'Change_Export_KG']\n",
    "    anthroRegByLuseProcess = pd.merge(pd.merge(baseTotals, predevTotals, how='left', left_on=[sourceRegStr,constituentStr,fuStr, processStr],\n",
    "                                               right_on = [sourceRegStr,constituentStr,fuStr, processStr]).reset_index(), reductionsMerged,\n",
    "                                      how='left', left_on=[sourceRegStr,constituentStr,fuStr, processStr], right_on = [sourceRegStr,constituentStr,fuStr, processStr]).reset_index()\n",
    "    #anthroRegByLuse.head(8)\n",
    "    \n",
    "    ##Need to add in a few export differences for totalising\n",
    "    anthroRegByLuseProcess[D2CRedOnly] = np.where(anthroRegByLuseProcess[D2CExportStr] < anthroRegByLuseProcess[baseExportStr],\n",
    "                                                  anthroRegByLuseProcess[baseExportStr] - anthroRegByLuseProcess[D2CExportStr],0)\n",
    "    anthroRegByLuseProcess[AllBRedOnly] = np.where(anthroRegByLuseProcess[AllBExportStr] < anthroRegByLuseProcess[baseExportStr],\n",
    "                                                   anthroRegByLuseProcess[baseExportStr] - anthroRegByLuseProcess[AllBExportStr],0)\n",
    "    anthroRegByLuseProcess[AllARedOnly] = np.where(anthroRegByLuseProcess[AllAExportStr] < anthroRegByLuseProcess[baseExportStr],\n",
    "                                                   anthroRegByLuseProcess[baseExportStr] - anthroRegByLuseProcess[AllAExportStr],0)\n",
    "    \n",
    "    #Lets add the totals and prec reduction estimates before exporting\n",
    "    #theFileOut = baseOutDir + '\\\\' + thisRegID + '_RC2017_AddScenarios_AnthroRegByLanduseProcess.csv'\n",
    "    #anthroRegByLuseProcess.to_csv(theFileOut, index=False)\n",
    "    ##print(\"Saved \" + theFileOut)\n",
    "    \n",
    "    regExports = anthroRegByLuseProcess.groupby([sourceRegStr, constituentStr, groupStr]).agg({predevExportStr:'sum',\n",
    "                                                                                               baseExportStr:'sum',\n",
    "                                                                                               D2CExportStr:'sum',\n",
    "                                                                                               AllBExportStr:'sum',\n",
    "                                                                                               AllAExportStr:'sum',\n",
    "                                                                                               D2CRedOnly:'sum',\n",
    "                                                                                               AllBRedOnly:'sum',\n",
    "                                                                                               AllARedOnly:'sum'})\n",
    "    \n",
    "    regExports[modelRegStr] = regName\n",
    "    regExports[D2CPercRedStr] = (regExports[baseExportStr] - regExports[D2CExportStr]).div(regExports[baseExportStr] - regExports[predevExportStr]).mul(100)\n",
    "    regExports[AllBPercRedStr] = (regExports[baseExportStr] - regExports[AllBExportStr]).div(regExports[baseExportStr] - regExports[predevExportStr]).mul(100)\n",
    "    regExports[AllAPercRedStr] = (regExports[baseExportStr] - regExports[AllAExportStr]).div(regExports[baseExportStr] - regExports[predevExportStr]).mul(100)\n",
    "    \n",
    "    regExports = regExports.rename(columns={predevExportStr:regpredevExportStr,baseExportStr:regbaseExportStr,\n",
    "                                            D2CExportStr:regD2CExportStr, AllBExportStr:regAllBExportStr,\n",
    "                                            AllAExportStr:regAllAExportStr, D2CRedOnly:D2CRedOnlyTotal,\n",
    "                                           AllBRedOnly:AllBRedOnlyTotal, AllARedOnly:AllARedOnlyTotal})\n",
    "    \n",
    "    regExports = regExports.reset_index()\n",
    "    regExports = regExports[[modelRegStr, sourceRegStr, constituentStr, groupStr, regpredevExportStr, regbaseExportStr,\n",
    "                             regD2CExportStr, D2CPercRedStr, regAllBExportStr, AllBPercRedStr, regAllAExportStr, AllAPercRedStr,\n",
    "                            D2CRedOnlyTotal, AllBRedOnlyTotal, AllARedOnlyTotal]]\n",
    "    #print(regExports.head(15))\n",
    "    \n",
    "    #keepp groupStr in join, so as not to duplicate columns\n",
    "    anthroRegByLuseProcess = pd.merge(anthroRegByLuseProcess, regExports, how='left',\n",
    "                                      left_on=[sourceRegStr,groupStr,constituentStr], right_on = [sourceRegStr,groupStr,constituentStr])\n",
    "    \n",
    "    \n",
    "    #Now some final assessment of how much reduction is attributable to each FU/process combination\n",
    "    #D2CRedAttributed\n",
    "    \n",
    "    anthroRegByLuseProcess[D2CRedAttributed] = np.where((anthroRegByLuseProcess[D2CPercRedStr] > 0) & (anthroRegByLuseProcess[D2CRedOnlyTotal] > 0),\n",
    "                                                       (anthroRegByLuseProcess[D2CRedOnly] / anthroRegByLuseProcess[D2CRedOnlyTotal]) * anthroRegByLuseProcess[D2CPercRedStr],\n",
    "                                                       0)\n",
    "    \n",
    "    anthroRegByLuseProcess[AllBRedAttributed] = np.where((anthroRegByLuseProcess[AllBPercRedStr] > 0) & (anthroRegByLuseProcess[AllBRedOnlyTotal] > 0),\n",
    "                                                       (anthroRegByLuseProcess[AllBRedOnly] / anthroRegByLuseProcess[AllBRedOnlyTotal]) * anthroRegByLuseProcess[AllBPercRedStr],\n",
    "                                                       0)\n",
    "    anthroRegByLuseProcess[AllARedAttributed] = np.where((anthroRegByLuseProcess[AllAPercRedStr] > 0) & (anthroRegByLuseProcess[AllARedOnlyTotal] > 0),\n",
    "                                                       (anthroRegByLuseProcess[AllARedOnly] / anthroRegByLuseProcess[AllARedOnlyTotal]) * anthroRegByLuseProcess[AllAPercRedStr],\n",
    "                                                       0)\n",
    "\n",
    "    #print(anthroRegByLuseProcess.head(15))\n",
    "    #return\n",
    "\n",
    "    #thisIndex = [sourceRegStr, groupStr, constituentStr, fuStr, processStr,\n",
    "    #                                                 'AREA_HA', baseSupplyStr, baseExportStr, predevSupplyStr, predevExportStr,\n",
    "    #                                                D2CSupplyStr, D2CExportStr, AllBSupplyStr, AllBExportStr, AllASupplyStr, AllAExportStr,\n",
    "    #                                                D2CPercRedStr, AllBPercRedStr, AllAPercRedStr]\n",
    "    #anthroRegByLuseProcess.index = thisIndex\n",
    "    \n",
    "    anthroRegByLuseProcess = anthroRegByLuseProcess[[sourceRegStr, groupStr, constituentStr, fuStr, processStr,\n",
    "                                                     'AREA_HA', baseSupplyStr, baseExportStr, predevSupplyStr, predevExportStr,\n",
    "                                                    D2CSupplyStr, D2CExportStr, AllBSupplyStr, AllBExportStr, AllASupplyStr, AllAExportStr,\n",
    "                                                    regpredevExportStr, regbaseExportStr, regD2CExportStr, regAllBExportStr, regAllAExportStr,\n",
    "                                                    D2CPercRedStr, AllBPercRedStr, AllAPercRedStr,\n",
    "                                                    D2CRedOnly, AllBRedOnly, AllARedOnly,\n",
    "                                                    D2CRedOnlyTotal, AllBRedOnlyTotal, AllARedOnlyTotal,\n",
    "                                                    D2CRedAttributed, AllBRedAttributed, AllARedAttributed]]\n",
    "    \n",
    "        \n",
    "    theFileOut = baseOutDir + '\\\\' + thisRegID + '_RC2017_AddScenarios_AnthroRegByLanduseProcess.csv'\n",
    "    anthroRegByLuseProcess.to_csv(theFileOut, index=False)\n",
    "    \n",
    "    modelRegExports = regExports.groupby([modelRegStr, constituentStr, groupStr]).agg({regpredevExportStr:'sum',\n",
    "                                                                                       regbaseExportStr:'sum',\n",
    "                                                                                       regD2CExportStr:'sum',\n",
    "                                                                                       regAllBExportStr:'sum',\n",
    "                                                                                       regAllAExportStr:'sum',\n",
    "                                                                                      D2CRedOnlyTotal:'sum',\n",
    "                                                                                      AllBRedOnlyTotal:'sum',\n",
    "                                                                                      AllARedOnlyTotal:'sum'})\n",
    "    modelRegExports[sourceRegStr] = regTotalStr\n",
    "    modelRegExports[D2CPercRedStr] = (modelRegExports[regbaseExportStr] - modelRegExports[regD2CExportStr]).div(modelRegExports[regbaseExportStr] - modelRegExports[regpredevExportStr]).mul(100)\n",
    "    modelRegExports[AllBPercRedStr] = (modelRegExports[regbaseExportStr] - modelRegExports[regAllBExportStr]).div(modelRegExports[regbaseExportStr] - modelRegExports[regpredevExportStr]).mul(100)\n",
    "    modelRegExports[AllAPercRedStr] = (modelRegExports[regbaseExportStr] - modelRegExports[regAllAExportStr]).div(modelRegExports[regbaseExportStr] - modelRegExports[regpredevExportStr]).mul(100)\n",
    "    modelRegExports = modelRegExports.reset_index()\n",
    "    modelRegExports = modelRegExports[[modelRegStr, sourceRegStr, constituentStr, groupStr, regpredevExportStr, regbaseExportStr,\n",
    "                                       regD2CExportStr, D2CPercRedStr, regAllBExportStr, AllBPercRedStr, regAllAExportStr, AllAPercRedStr,\n",
    "                                      D2CRedOnlyTotal, AllBRedOnlyTotal, AllARedOnlyTotal]]\n",
    "    ###modelRegExports.head(15)\n",
    "    regExports = regExports.append(modelRegExports, ignore_index=True)\n",
    "    \n",
    "    return regExports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "allExportsAndReductions = pd.DataFrame(columns=[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr,\n",
    "                                                baseExportStr, D2CExportStr, D2CPercRedStr, AllBExportStr, AllBPercRedStr,\n",
    "                                                AllAExportStr, AllAPercRedStr])\n",
    "\n",
    "#theseExports = calculateReductions('Burdekin', 'BU')\n",
    "#allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Burnett Mary', 'BM')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Burdekin', 'BU')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Cape York', 'CY')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Fitzroy', 'FI')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Mackay Whitsunday', 'MW')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Wet Tropics', 'WT')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "#theFileNameOut = outPath + '\\\\' + summariesOutFolder + '\\\\AllExportsAndReductions.csv'\n",
    "#allExportsAndReductions.to_csv(theFileNameOut, index=False)\n",
    "allExportsAndReductions.head(20)\n",
    "#print(allExportsAndReductions)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
