{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Robs summariser of RC10 regoinal Contributor tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#mainPath = 'P:\\projects\\RC9_ResultsSets\\RegContribTables'\n",
    "mainPath = r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth'\n",
    "outPath = r'P:\\projects\\RC10_ResultsSets'\n",
    "summariesOutFolder = 'SummariesWithProcessAusGov'\n",
    "baseFolderEnd = 'BASE_RC10'\n",
    "changeFolderEnd = 'CHANGE_RC10'\n",
    "predevFolderEnd = 'PREDEV_RC10'\n",
    "regContributorFileName = 'RegContributorDataGrid.csv'\n",
    "#outputCSVEnd = 'RegToOutlet_Alt.csv'\n",
    "outputCSVEnd = 'RegToOutlet.csv'\n",
    "baselineScenarioName = 'Baseline'\n",
    "changeScenarioName = 'Change'\n",
    "predevScenarioName = 'PreDev'\n",
    "reportCardString = 'RC2019'\n",
    "\n",
    "pathToContstitsToGrpFile = r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\constituentsToGroups.csv'\n",
    "\n",
    "#Must be utilised in regContributors that do NOT include nesting structures\n",
    "alternativeRegionsCSV = {'BM':r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\BM_ReportingRegions_Details.csv'}\n",
    "\n",
    "altRegLinker = 'Catchmt'\n",
    "standardRegName = 'RepReg'\n",
    "altRegColName = 'BASIN'\n",
    "origLinker = 'ModelElement'\n",
    "\n",
    "annLoadToStream = 'AnnLoadToStreamKG'\n",
    "annLoadToExport = 'AnnLoadToExportKG'\n",
    "\n",
    "#regionIDs = ['BU', 'BM', 'CY', 'FI', 'MW', 'WT']\n",
    "regionIDs = ['BM']\n",
    "#regionIDs = ['MW']\n",
    "\n",
    "scenarioToFolderDict = {baselineScenarioName:baseFolderEnd, changeScenarioName:changeFolderEnd, predevScenarioName:predevFolderEnd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outPath):\n",
    "    os.makedirs(outPath)\n",
    "    print(\"Made dir: \" + outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outPath + '\\\\' + summariesOutFolder):\n",
    "    os.makedirs(outPath + '\\\\' + summariesOutFolder)\n",
    "    print(\"Made dir: \" + outPath + '\\\\' + summariesOutFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathInfo(regionIDString, scenarioString):\n",
    "    fileIn = mainPath + '\\\\' + regionIDString + '\\\\Model_Outputs\\\\' + regionIDString + '_' + scenarioToFolderDict[scenarioString] + '\\\\' + regContributorFileName\n",
    "    fileOut = outPath + '\\\\' + summariesOutFolder + '\\\\' + regionIDString + '_' + reportCardString + '_' + scenarioString + '_' + outputCSVEnd\n",
    "    return fileIn, fileOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceSummaryFromRegContrib(regionIDString, scenarioName):\n",
    "    \n",
    "    theFileIn, theFileOut = getPathInfo(regionIDString, scenarioName)\n",
    "    \n",
    "    print(\"Processing \" + theFileIn + \" Scenario: \" + scenarioName)\n",
    "    \n",
    "    rawcontrib = pd.read_csv(theFileIn)\n",
    "    \n",
    "    rawcontrib['SCENARIO'] = scenarioName\n",
    "    rawcontrib[annLoadToStream] = rawcontrib['LoadToStream (kg)'].div(rawcontrib['Num_Days']).mul(365.25)\n",
    "    rawcontrib[annLoadToExport] = rawcontrib['LoadToRegExport (kg)'].div(rawcontrib['Num_Days']).mul(365.25)\n",
    "    rawcontrib['AreaHA'] = rawcontrib['AreaM2'].div(10000)\n",
    "    \n",
    "    if regionIDString in alternativeRegionsCSV:\n",
    "        print(\"Reading alternative regionalistaion for \" + regionIDString)\n",
    "        altDetsDF = pd.read_csv(alternativeRegionsCSV[regionIDString])\n",
    "        combinedDF = pd.merge(rawcontrib, altDetsDF, how='left', left_on=[origLinker], right_on = [altRegLinker])\n",
    "        #Transfer vals\n",
    "        combinedDF['Rep_Region'] = combinedDF[altRegColName]\n",
    "        #Drop cols\n",
    "        #where 1 is the axis number (0 for rows and 1 for columns.)\n",
    "        combinedDF = combinedDF.drop(altRegColName, 1)\n",
    "        combinedDF = combinedDF.drop(standardRegName, 1)\n",
    "        combinedDF = combinedDF.drop(altRegLinker, 1)\n",
    "        rawcontrib = combinedDF\n",
    "    \n",
    "    ### Can keep reporting region in the area table, as this is our Non-Nested notebook\n",
    "    catchFuArea = pd.DataFrame(rawcontrib.groupby(['Rep_Region','ModelElement','FU']).agg({'AreaHA':'first'})).reset_index()\n",
    "    regFuArea = pd.DataFrame(catchFuArea.groupby(['Rep_Region','FU']).agg({'AreaHA':'sum'})).reset_index()\n",
    "    \n",
    "    #regLuseSummary = pd.DataFrame(rawcontrib[rawcontrib['Constituent'].isin(selectedConstituents)].groupby(['Rep_Region','Constituent','FU','Process']).agg({'AnnLoadToStreamKG':'sum','AnnLoadToExportKG':'sum'})).reset_index()\n",
    "    regLuseSummary = pd.DataFrame(rawcontrib.groupby(['SCENARIO','Rep_Region','Constituent','FU','Process']).agg({annLoadToStream:'sum',annLoadToExport:'sum'})).reset_index()\n",
    "    \n",
    "    ### Join/merge with Regional Areas\n",
    "    regLuseSumPlusArea = pd.merge(regLuseSummary, regFuArea, how='left', left_on=['Rep_Region','FU'], right_on = ['Rep_Region','FU'])\n",
    "    \n",
    "    regLuseSumPlusArea.to_csv(theFileOut, index=False)\n",
    "    \n",
    "    print(\"Saved \" + theFileOut)\n",
    "    \n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: BM Baseline\n",
      "Processing \\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\BM\\Model_Outputs\\BM_BASE_RC10\\RegContributorDataGrid.csv Scenario: Baseline\n",
      "Reading alternative regionalistaion for BM\n",
      "Saved P:\\projects\\RC10_ResultsSets\\SummariesWithProcessAusGov\\BM_RC2019_Baseline_RegToOutlet.csv\n",
      "Doing: BM Change\n",
      "Processing \\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\BM\\Model_Outputs\\BM_CHANGE_RC10\\RegContributorDataGrid.csv Scenario: Change\n",
      "Reading alternative regionalistaion for BM\n",
      "Saved P:\\projects\\RC10_ResultsSets\\SummariesWithProcessAusGov\\BM_RC2019_Change_RegToOutlet.csv\n",
      "Doing: BM PreDev\n",
      "Processing \\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\BM\\Model_Outputs\\BM_PREDEV_RC10\\RegContributorDataGrid.csv Scenario: PreDev\n",
      "Reading alternative regionalistaion for BM\n",
      "Saved P:\\projects\\RC10_ResultsSets\\SummariesWithProcessAusGov\\BM_RC2019_PreDev_RegToOutlet.csv\n",
      "Finished first summary\n"
     ]
    }
   ],
   "source": [
    "#List out the processes\n",
    "\n",
    "for theReg in regionIDs:\n",
    "    \n",
    "    for scenario in scenarioToFolderDict.keys():\n",
    "        \n",
    "        print(\"Doing: \" + theReg + \" \" + scenario)\n",
    "        produceSummaryFromRegContrib(theReg, scenario)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finished first summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build relationships of constituent names to groups\n",
    "#tssGrp = 'TSS'\n",
    "#tnGrp = 'TN'\n",
    "#tpGrp = 'TP'\n",
    "#ps2Grp = 'PSII'\n",
    "#nonps2Grp = 'non-PSII'\n",
    "##Nope, will read in a CSV to DataFrame instead, thus joing will 'drop' flow from this comparison\n",
    "#constToGrp = {'Sediment - Fine':tssGrp}\n",
    "\n",
    "constToGrp = pd.read_csv(pathToContstitsToGrpFile)\n",
    "\n",
    "baseSupplyStr = 'Base_Supply_KG'\n",
    "baseExportStr = 'Base_Export_KG'\n",
    "changeSupplyStr = 'Change_Supply_KG'\n",
    "changeExportStr = 'Change_Export_KG'\n",
    "predevSupplyStr = 'PreDev_Supply_KG'\n",
    "predevExportStr = 'PreDev_Export_KG'\n",
    "repRegStr = 'Rep_Region'\n",
    "sourceRegStr = 'Source Region'\n",
    "constituentStr = 'Constituent'\n",
    "fuStr = 'FU'\n",
    "groupStr = 'GROUP'\n",
    "modelRegStr = 'MODELREG'\n",
    "percRedStr = 'PercReduction'\n",
    "regTotalStr = 'REGIONAL TOTAL'\n",
    "processStr = 'Process'\n",
    "\n",
    "#allExportsAndReductions = pd.DataFrame(columns=[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr, baseExportStr, changeExportStr, percRedStr])\n",
    "#allExportsAndReductions = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now we would be reading in known summary files\n",
    "\n",
    "def calculateReductions(regName, thisRegID):\n",
    "    \n",
    "    unneededFile, theBaseSummaryFile = getPathInfo(thisRegID, baselineScenarioName)\n",
    "    unneededFile, theChangeSummaryFile = getPathInfo(thisRegID, changeScenarioName)\n",
    "    unneededFile, thePreDevSummaryFile = getPathInfo(thisRegID, predevScenarioName)\n",
    "    \n",
    "    #print(\"Reading: \" + theBaseSummaryFile)\n",
    "    baseSummaryDF = pd.read_csv(theBaseSummaryFile)\n",
    "    #print(\"Reading: \" + theChangeSummaryFile)\n",
    "    changeSummaryDF = pd.read_csv(theChangeSummaryFile)\n",
    "    #print(\"Reading: \" + thePreDevSummaryFile)\n",
    "    predevSummaryDF = pd.read_csv(thePreDevSummaryFile)\n",
    "    \n",
    "    #inner drops out those that don't merge, left keep them\n",
    "    baseTotals = pd.merge(baseSummaryDF.groupby([repRegStr,constituentStr,fuStr,processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum', 'AreaHA':'first'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT']).reset_index()\n",
    "    baseTotals = baseTotals.rename(columns={repRegStr:sourceRegStr,'AreaHA':'AREA_HA',annLoadToStream:baseSupplyStr, annLoadToExport:baseExportStr})\n",
    "    baseTotals = baseTotals[[sourceRegStr, groupStr, constituentStr, fuStr, processStr, 'AREA_HA', baseSupplyStr, baseExportStr]]\n",
    "    #baseTotals.head(40)\n",
    "    \n",
    "    predevTotals = pd.merge(predevSummaryDF.groupby([repRegStr,constituentStr,fuStr,processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT']).reset_index()\n",
    "    predevTotals = predevTotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:predevSupplyStr, annLoadToExport:predevExportStr})\n",
    "    predevTotals = predevTotals[[sourceRegStr, constituentStr, fuStr, processStr, predevSupplyStr, predevExportStr]]\n",
    "    \n",
    "    changeTotals = pd.merge(changeSummaryDF.groupby([repRegStr,constituentStr,fuStr,processStr]).agg({annLoadToStream:'sum', annLoadToExport:'sum'}).reset_index(), constToGrp, how='inner', left_on=[constituentStr], right_on = ['CONSTITUENT'])\n",
    "    changeTotals = changeTotals.rename(columns={repRegStr:sourceRegStr,annLoadToStream:changeSupplyStr, annLoadToExport:changeExportStr})\n",
    "    changeTotals = changeTotals[[sourceRegStr, constituentStr, fuStr, processStr, changeSupplyStr, changeExportStr]]\n",
    "    #changeTotals.head(8)\n",
    "    \n",
    "    #, columns=['Rep_Region', 'GROUP', 'Constituent', 'FU', 'AREA_HA', 'Base_Supply_KG', 'Base_Export_KG', 'PreDev_Supply_KG', 'PreDev_Export_KG', 'Change_Supply_KG', 'Change_Export_KG']\n",
    "    anthroRegByLuse = pd.merge(pd.merge(baseTotals, predevTotals, how='left', left_on=[sourceRegStr,constituentStr,fuStr,processStr],\n",
    "                                        right_on = [sourceRegStr,constituentStr,fuStr,processStr]).reset_index(), changeTotals, how='left',\n",
    "                               left_on=[sourceRegStr,constituentStr,fuStr,processStr],\n",
    "                               right_on = [sourceRegStr,constituentStr,fuStr,processStr])\n",
    "    #anthroRegByLuse.head(8)\n",
    "    \n",
    "    theFileOut = outPath + '\\\\' + summariesOutFolder + '\\\\' + thisRegID + '_RC2019_AnthroRegByLanduseProcess.csv'\n",
    "    anthroRegByLuse.to_csv(theFileOut, index=False)\n",
    "    #print(\"Saved \" + theFileOut)\n",
    "    \n",
    "    regExports = anthroRegByLuse.groupby([sourceRegStr, constituentStr, groupStr]).agg({predevExportStr:'sum', baseExportStr:'sum', changeExportStr:'sum'})\n",
    "    \n",
    "    regExports[modelRegStr] = regName\n",
    "    regExports[percRedStr] = (regExports[baseExportStr] - regExports[changeExportStr]).div(regExports[baseExportStr] - regExports[predevExportStr]).mul(100)\n",
    "    regExports = regExports.reset_index()\n",
    "    regExports = regExports[[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr, baseExportStr, changeExportStr, percRedStr]]\n",
    "    #regExports.head(15)\n",
    "    \n",
    "    modelRegExports = regExports.groupby([modelRegStr, constituentStr, groupStr]).agg({predevExportStr:'sum', baseExportStr:'sum', changeExportStr:'sum'})\n",
    "    modelRegExports[sourceRegStr] = regTotalStr\n",
    "    modelRegExports[percRedStr] = (modelRegExports[baseExportStr] - modelRegExports[changeExportStr]).div(modelRegExports[baseExportStr] - modelRegExports[predevExportStr]).mul(100)\n",
    "    modelRegExports = modelRegExports.reset_index()\n",
    "    modelRegExports = modelRegExports[[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr, baseExportStr, changeExportStr, percRedStr]]\n",
    "    ##modelRegExports.head(15)\n",
    "    regExports = regExports.append(modelRegExports, ignore_index=True)\n",
    "    \n",
    "    return regExports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODELREG</th>\n",
       "      <th>Source Region</th>\n",
       "      <th>Constituent</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>PreDev_Export_KG</th>\n",
       "      <th>Base_Export_KG</th>\n",
       "      <th>Change_Export_KG</th>\n",
       "      <th>PercReduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>N_DIN</td>\n",
       "      <td>TN</td>\n",
       "      <td>2.959363e+04</td>\n",
       "      <td>3.054304e+04</td>\n",
       "      <td>3.054628e+04</td>\n",
       "      <td>-0.341223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>N_DON</td>\n",
       "      <td>TN</td>\n",
       "      <td>2.594922e+05</td>\n",
       "      <td>2.599704e+05</td>\n",
       "      <td>2.599704e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>N_Particulate</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.277489e+04</td>\n",
       "      <td>5.292315e+04</td>\n",
       "      <td>5.283505e+04</td>\n",
       "      <td>0.219434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>P_DOP</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.180447e+04</td>\n",
       "      <td>1.206056e+04</td>\n",
       "      <td>1.206036e+04</td>\n",
       "      <td>0.078906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>P_FRP</td>\n",
       "      <td>TP</td>\n",
       "      <td>2.934435e+04</td>\n",
       "      <td>2.954212e+04</td>\n",
       "      <td>2.954192e+04</td>\n",
       "      <td>0.099621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>P_Particulate</td>\n",
       "      <td>TP</td>\n",
       "      <td>5.968885e+03</td>\n",
       "      <td>2.589925e+04</td>\n",
       "      <td>2.586184e+04</td>\n",
       "      <td>0.187707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Belyando</td>\n",
       "      <td>Sediment - Fine</td>\n",
       "      <td>TSS</td>\n",
       "      <td>9.312506e+06</td>\n",
       "      <td>4.370572e+07</td>\n",
       "      <td>4.367995e+07</td>\n",
       "      <td>0.074939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>N_DIN</td>\n",
       "      <td>TN</td>\n",
       "      <td>3.643923e+04</td>\n",
       "      <td>5.470745e+04</td>\n",
       "      <td>5.470745e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>N_DON</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.712119e+05</td>\n",
       "      <td>1.807114e+05</td>\n",
       "      <td>1.807114e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>N_Particulate</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.411692e+05</td>\n",
       "      <td>1.813361e+05</td>\n",
       "      <td>1.813361e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>P_DOP</td>\n",
       "      <td>TP</td>\n",
       "      <td>7.452347e+03</td>\n",
       "      <td>7.936113e+03</td>\n",
       "      <td>7.936113e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>P_FRP</td>\n",
       "      <td>TP</td>\n",
       "      <td>2.146319e+04</td>\n",
       "      <td>2.344667e+04</td>\n",
       "      <td>2.344667e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>P_Particulate</td>\n",
       "      <td>TP</td>\n",
       "      <td>5.000960e+04</td>\n",
       "      <td>6.258172e+04</td>\n",
       "      <td>6.258172e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Black</td>\n",
       "      <td>Sediment - Fine</td>\n",
       "      <td>TSS</td>\n",
       "      <td>2.630476e+07</td>\n",
       "      <td>4.930908e+07</td>\n",
       "      <td>4.930908e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>N_DIN</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.740177e+05</td>\n",
       "      <td>1.730348e+05</td>\n",
       "      <td>1.730532e+05</td>\n",
       "      <td>1.867196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>N_DON</td>\n",
       "      <td>TN</td>\n",
       "      <td>4.177061e+05</td>\n",
       "      <td>4.178435e+05</td>\n",
       "      <td>4.178435e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>N_Particulate</td>\n",
       "      <td>TN</td>\n",
       "      <td>3.610818e+05</td>\n",
       "      <td>2.058698e+06</td>\n",
       "      <td>2.054008e+06</td>\n",
       "      <td>0.276262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>P_DOP</td>\n",
       "      <td>TP</td>\n",
       "      <td>3.474376e+04</td>\n",
       "      <td>3.476300e+04</td>\n",
       "      <td>3.476301e+04</td>\n",
       "      <td>-0.029559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>P_FRP</td>\n",
       "      <td>TP</td>\n",
       "      <td>8.679194e+04</td>\n",
       "      <td>8.679805e+04</td>\n",
       "      <td>8.679806e+04</td>\n",
       "      <td>-0.096491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Burdekin</td>\n",
       "      <td>Bowen Bogie</td>\n",
       "      <td>P_Particulate</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.616497e+05</td>\n",
       "      <td>9.476932e+05</td>\n",
       "      <td>9.459175e+05</td>\n",
       "      <td>0.225901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODELREG Source Region      Constituent GROUP  PreDev_Export_KG  \\\n",
       "0   Burdekin      Belyando            N_DIN    TN      2.959363e+04   \n",
       "1   Burdekin      Belyando            N_DON    TN      2.594922e+05   \n",
       "2   Burdekin      Belyando    N_Particulate    TN      1.277489e+04   \n",
       "3   Burdekin      Belyando            P_DOP    TP      1.180447e+04   \n",
       "4   Burdekin      Belyando            P_FRP    TP      2.934435e+04   \n",
       "5   Burdekin      Belyando    P_Particulate    TP      5.968885e+03   \n",
       "6   Burdekin      Belyando  Sediment - Fine   TSS      9.312506e+06   \n",
       "7   Burdekin         Black            N_DIN    TN      3.643923e+04   \n",
       "8   Burdekin         Black            N_DON    TN      1.712119e+05   \n",
       "9   Burdekin         Black    N_Particulate    TN      1.411692e+05   \n",
       "10  Burdekin         Black            P_DOP    TP      7.452347e+03   \n",
       "11  Burdekin         Black            P_FRP    TP      2.146319e+04   \n",
       "12  Burdekin         Black    P_Particulate    TP      5.000960e+04   \n",
       "13  Burdekin         Black  Sediment - Fine   TSS      2.630476e+07   \n",
       "14  Burdekin   Bowen Bogie            N_DIN    TN      1.740177e+05   \n",
       "15  Burdekin   Bowen Bogie            N_DON    TN      4.177061e+05   \n",
       "16  Burdekin   Bowen Bogie    N_Particulate    TN      3.610818e+05   \n",
       "17  Burdekin   Bowen Bogie            P_DOP    TP      3.474376e+04   \n",
       "18  Burdekin   Bowen Bogie            P_FRP    TP      8.679194e+04   \n",
       "19  Burdekin   Bowen Bogie    P_Particulate    TP      1.616497e+05   \n",
       "\n",
       "    Base_Export_KG  Change_Export_KG  PercReduction  \n",
       "0     3.054304e+04      3.054628e+04      -0.341223  \n",
       "1     2.599704e+05      2.599704e+05       0.000000  \n",
       "2     5.292315e+04      5.283505e+04       0.219434  \n",
       "3     1.206056e+04      1.206036e+04       0.078906  \n",
       "4     2.954212e+04      2.954192e+04       0.099621  \n",
       "5     2.589925e+04      2.586184e+04       0.187707  \n",
       "6     4.370572e+07      4.367995e+07       0.074939  \n",
       "7     5.470745e+04      5.470745e+04       0.000000  \n",
       "8     1.807114e+05      1.807114e+05       0.000000  \n",
       "9     1.813361e+05      1.813361e+05       0.000000  \n",
       "10    7.936113e+03      7.936113e+03       0.000000  \n",
       "11    2.344667e+04      2.344667e+04       0.000000  \n",
       "12    6.258172e+04      6.258172e+04       0.000000  \n",
       "13    4.930908e+07      4.930908e+07       0.000000  \n",
       "14    1.730348e+05      1.730532e+05       1.867196  \n",
       "15    4.178435e+05      4.178435e+05       0.000000  \n",
       "16    2.058698e+06      2.054008e+06       0.276262  \n",
       "17    3.476300e+04      3.476301e+04      -0.029559  \n",
       "18    8.679805e+04      8.679806e+04      -0.096491  \n",
       "19    9.476932e+05      9.459175e+05       0.225901  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allExportsAndReductions = pd.DataFrame(columns=[modelRegStr, sourceRegStr, constituentStr, groupStr, predevExportStr, baseExportStr, changeExportStr, percRedStr])\n",
    "\n",
    "theseExports = calculateReductions('Burdekin', 'BU')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Burnett Mary', 'BM')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "#theseExports = calculateReductions('Cape York', 'CY')\n",
    "#allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theseExports = calculateReductions('Fitzroy', 'FI')\n",
    "allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "#theseExports = calculateReductions('Mackay Whitsunday', 'MW')\n",
    "#allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "#theseExports = calculateReductions('Wet Tropics', 'WT')\n",
    "#allExportsAndReductions = allExportsAndReductions.append(theseExports, ignore_index=True)\n",
    "\n",
    "theFileNameOut = outPath + '\\\\' + summariesOutFolder + '\\\\AllExportsAndReductions_FromProcess.csv'\n",
    "allExportsAndReductions.to_csv(theFileNameOut, index=False)\n",
    "allExportsAndReductions.head(20)\n",
    "#print(allExportsAndReductions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
