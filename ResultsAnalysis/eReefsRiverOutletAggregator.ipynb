{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "riverCol = 'Major River'\n",
    "elementCol = 'Network Element'\n",
    "\n",
    "#Constituents = ['Sediment - Fine', 'Sediment - Coarse', 'N_Particulate', 'N_DIN', 'N_DON', 'P_Particulate', 'P_DOP', 'P_FRP']\n",
    "Constituents = ['Ametryn', 'S-metolachlor', 'Atrazine', 'Diuron', 'Hexazinone', 'Tebuthiuron', '24-D'\n",
    "                , 'Paraquat', 'Glyphosate', 'Chlorsulfuron', 'Diquat', 'Fluroxypyr', 'Haloxyfop', 'Imazapic'\n",
    "               , 'Imazethapyr', 'Isoxaflutole', 'MCPA', 'Metribuzin', 'Metsulfuron-methyl', 'Pendimethalin', 'Simazine'\n",
    "               , 'Terbuthylazin', 'Trifluralin', 'Aciflurofen', 'Chlorpyrifos', 'Fipronil', 'Imidacloprid', 'Prometryn', 'Triclopyr']\n",
    "\n",
    "#elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BurdekinElementMapper.csv'\n",
    "#mainPath = r'P:\\projects\\MichaelWarne\\Models\\results\\Burdekin Rebuild 2014\\BU_msPAF_Calibrated_503\\TimeSeries'\n",
    "#outPath = r'C:\\DDrive\\RC10PesticideProjs\\CSIROAggregatedOutlets\\Burdekin'\n",
    "\n",
    "#elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BurnettMaryElementMapper.csv'\n",
    "#mainPath = r'C:\\DDrive\\RC10PesticideProjs\\results\\Burnett Mary Rebuild 2014\\BM_RC10_MSPAF\\TimeSeries'\n",
    "#outPath = r'C:\\DDrive\\RC10PesticideProjs\\CSIROAggregatedOutlets\\BurnettMary'\n",
    "\n",
    "#elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\FitzroyElementMapper.csv'\n",
    "#mainPath = r'C:\\DDrive\\RC10PesticideProjs\\results\\FI RC2018\\FI_RC10_msPAF\\TimeSeries'\n",
    "#outPath = r'C:\\DDrive\\RC10PesticideProjs\\CSIROAggregatedOutlets\\Fitzroy'\n",
    "\n",
    "#elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\MackayWhitsundayElementMapper.csv'\n",
    "#mainPath = r'C:\\DDrive\\RC10PesticideProjs\\results\\MW_DS_2015\\MW_Rc10_msPAF\\TimeSeries'\n",
    "#outPath = r'C:\\DDrive\\RC10PesticideProjs\\CSIROAggregatedOutlets\\MackayWhitsunday'\n",
    "\n",
    "elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\WetTropicsElementMapper.csv'\n",
    "mainPath = r'C:\\DDrive\\RC10PesticideProjs\\results\\WetTropics_DS_2015\\WT_RC10_msPAF\\TimeSeries'\n",
    "outPath = r'C:\\DDrive\\RC10PesticideProjs\\CSIROAggregatedOutlets\\WetTropics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made dir: C:\\DDrive\\RC10PesticideProjs\\CSIROAggregated\\WetTropics\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outPath):\n",
    "    os.makedirs(outPath)\n",
    "    print(\"Made dir: \" + outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RiverElements = {}\n",
    "elementsTable = pd.read_csv(elementMapperCSV)\n",
    "\n",
    "for index, row in elementsTable.iterrows():\n",
    "    if not row[riverCol] in RiverElements.keys():\n",
    "        RiverElements[row[riverCol]] = []\n",
    "    \n",
    "    RiverElements[row[riverCol]].append(row[elementCol])\n",
    "\n",
    "\n",
    "#print(RiverElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done\n"
     ]
    }
   ],
   "source": [
    "#Set up the totals first\n",
    "riverTotals = {}\n",
    "for theRiver in RiverElements.keys():\n",
    "    riverTotals[theRiver] = pd.DataFrame()\n",
    "\n",
    "#Now data\n",
    "\n",
    "theFlowsDIR = os.path.join(mainPath,'Flows')\n",
    "for theRiver in RiverElements.keys():\n",
    "    #We'll want flows first\n",
    "    eleCount = 0\n",
    "    flowFrame = pd.DataFrame()\n",
    "    outputFields = ['Date']\n",
    "    for theElement in RiverElements[theRiver]:\n",
    "        for fname in os.listdir(theFlowsDIR):\n",
    "            if theElement in fname:\n",
    "                #print(\"For this river: \" + theRiver + \" we have this file: \" + fname)\n",
    "                flowFilePath = os.path.join(theFlowsDIR,fname)\n",
    "                flowData = pd.read_csv(flowFilePath)\n",
    "                flowData.columns = ['Date', theElement]\n",
    "                #riverTotals[theRiver].columns.drop(theElement)\n",
    "                outputFields.append(theElement)\n",
    "                if eleCount == 0:\n",
    "                    #Get the structure for our totals first\n",
    "                    riverTotals[theRiver] = flowData\n",
    "                    riverTotals[theRiver].drop(theElement, axis=1, inplace=True)\n",
    "                    #Now process stuff\n",
    "                    flowFrame = flowData\n",
    "                    #flowFrame.columns = ['Date', theElement]\n",
    "                    #flowFrame['Date'] = flowData['Date']\n",
    "                    #flowFrame[theElement] = flowData.iloc[:1].values#This sould give the 2nd column\n",
    "                else:\n",
    "                    #Join...??\n",
    "                    #flowFrame[theElement] = flowData.iloc[:1].values\n",
    "                    flowFrame = pd.merge(flowFrame, flowData, how='left', left_on=['Date'], right_on=['Date'])\n",
    "                \n",
    "                eleCount += 1\n",
    "    #Totals\n",
    "    #The .iloc[:, 1:] should exclude our first col, Date, from the sum\n",
    "    #flowFrame['Flow_cumecs'] = flowFrame.iloc[:, 1:].sum(axis=1)\n",
    "    flowFrame['Flow_cumecs'] = flowFrame.sum(axis=1)\n",
    "    #Write out flow\n",
    "    theOutFlowFile = os.path.join(outPath, \"Flow \" + theRiver + \" cubicmetrespersecond.csv\")\n",
    "    flowFrame.to_csv(theOutFlowFile, index=False)\n",
    "    #Need to join flow Total to RiverTotals\n",
    "    riverTotals[theRiver] = pd.merge(riverTotals[theRiver], flowFrame[['Date', 'Flow_cumecs']], how='left', left_on=['Date'], right_on=['Date'])\n",
    "\n",
    "#Now water quality\n",
    "for theWQBit in Constituents:\n",
    "    wqPath = os.path.join(mainPath, theWQBit)\n",
    "    if not os.path.exists(wqPath):\n",
    "        continue\n",
    "    \n",
    "    for theRiver in RiverElements.keys():\n",
    "        #We'll want flows first\n",
    "        eleCount = 0\n",
    "        wqFrame = pd.DataFrame()\n",
    "        outputFields = ['Date']\n",
    "        for theElement in RiverElements[theRiver]:\n",
    "            for fname in os.listdir(wqPath):\n",
    "                if theElement in fname:\n",
    "                    #print(\"For this river: \" + theRiver + \" we have this file: \" + fname)\n",
    "                    wqFilePath = os.path.join(wqPath,fname)\n",
    "                    wqData = pd.read_csv(wqFilePath)\n",
    "                    wqData.columns = ['Date', theElement]\n",
    "                    outputFields.append(theElement)\n",
    "                    if eleCount == 0:\n",
    "                        wqFrame = wqData\n",
    "                    else:\n",
    "                        wqFrame = pd.merge(wqFrame, wqData, how='left', left_on=['Date'], right_on=['Date'])\n",
    "                \n",
    "                    eleCount += 1\n",
    "        #Totals\n",
    "        #wqFrame[theRiver + '_kg'] = wqFrame.iloc[:, 1:].sum(axis=1)\n",
    "        wqFrame[theRiver + '_kg'] = wqFrame.sum(axis=1)\n",
    "        #Write out flow\n",
    "        theOutFlowFile = os.path.join(outPath, theWQBit + \" \" + theRiver + \" kilograms.csv\")\n",
    "        wqFrame.to_csv(theOutFlowFile, index=False)\n",
    "        #Join to totals\n",
    "        #rename constituent total first\n",
    "        wqFrame.rename(columns={theRiver + '_kg':theWQBit + '_kg'}, inplace=True)\n",
    "        riverTotals[theRiver] = pd.merge(riverTotals[theRiver], wqFrame[['Date', theWQBit + '_kg']], how='left', left_on=['Date'], right_on=['Date'])\n",
    "\n",
    "\n",
    "#Now write totals files\n",
    "for theRiver in RiverElements.keys():\n",
    "    theOutTotalsFile = os.path.join(outPath, theRiver + \" Totals.csv\")\n",
    "    riverTotals[theRiver].to_csv(theOutTotalsFile, index=False)\n",
    "\n",
    "\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
