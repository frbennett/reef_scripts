{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Robs summariser of RC8 regoinal Contributor tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#mainPath = 'P:\\projects\\RC9_ResultsSets\\RegContribTables'\n",
    "# mainPath = r'P:\\projects\\RC10_ResultsSets\\SummariesWithProcessAusGov'\n",
    "# reportCardString = 'RC2019'\n",
    "#mainPath = r'P:\\projects\\RC8_ResultsSets\\SummariesWithProcess'\n",
    "#reportCardString = 'RC2016'\n",
    "\n",
    "mainPath = r'P:\\projects\\RC8_ResultsSets\\SummariesWithProcessRC10regions'\n",
    "reportCardString = 'RC2016'\n",
    "\n",
    "#outPath = r'P:\\projects\\RC10_ResultsSets'\n",
    "#summariesOutFolder = 'SummariesWithProcessAusGov'\n",
    "# baseFolderEnd = 'BASE_RC10'\n",
    "# changeFolderEnd = 'CHANGE_RC10'\n",
    "# predevFolderEnd = 'PREDEV_RC10'\n",
    "processFileName = 'AnthroRegByLanduseProcess.csv'\n",
    "outputCSVEnd = 'ProcessExportContribution.csv'\n",
    "\n",
    "fieldName = 'Export_KG'\n",
    "\n",
    "#pathToContstitsToGrpFile = r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\constituentsToGroups.csv'\n",
    "\n",
    "##Must be utilised in regContributors that do NOT include nesting structures\n",
    "#alternativeRegionsCSV = {'FI':r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\FI_ReportingRegions_Details.csv',\n",
    "#                        'BU':r'\\\\athenasmb\\pdreef\\RC10_RC2019\\RC10_RC2019_ResultsSets_PointOfTruth\\BU_ReportingRegions_Details.csv'}\n",
    "\n",
    "#altRegLinker = 'Catchmt'\n",
    "#standardRegName = 'RepReg'\n",
    "#altRegColName = 'AUSGMCAS'\n",
    "#origLinker = 'ModelElement'\n",
    "\n",
    "annLoadToStream = 'AnnLoadToStreamKG'\n",
    "annLoadToExport = 'AnnLoadToExportKG'\n",
    "\n",
    "#regionIDs = ['BU', 'BM', 'CY', 'FI', 'MW', 'WT']\n",
    "regionIDs = ['BU']\n",
    "scenarios = ['Base','PreDev','Change']\n",
    "\n",
    "constitsList = ['Sediment - Fine', 'N_DIN']\n",
    "\n",
    "#scenarioToFolderDict = {baselineScenarioName:baseFolderEnd, changeScenarioName:changeFolderEnd, predevScenarioName:predevFolderEnd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(outPath):\n",
    "#     os.makedirs(outPath)\n",
    "#     print(\"Made dir: \" + outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(outPath + '\\\\' + summariesOutFolder):\n",
    "#     os.makedirs(outPath + '\\\\' + summariesOutFolder)\n",
    "#     print(\"Made dir: \" + outPath + '\\\\' + summariesOutFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathInfo(regionIDString):\n",
    "    fileIn = mainPath + '\\\\' + regionIDString + '_' + reportCardString + '_' + processFileName\n",
    "    fileOut = mainPath + '\\\\' + regionIDString + '_' + reportCardString + '_' + outputCSVEnd\n",
    "    return fileIn, fileOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceSummaryFromProcessFile(regionIDString):\n",
    "    \n",
    "    theFileIn, theFileOut = getPathInfo(regionIDString)\n",
    "    \n",
    "    print(\"Processing \" + theFileIn)\n",
    "    \n",
    "    rawcontrib = pd.read_csv(theFileIn)\n",
    "    \n",
    "    filtered = rawcontrib.loc[rawcontrib['Constituent'].isin(constitsList)]\n",
    "    \n",
    "    groupedData = filtered.groupby(['Source Region','Constituent','Process']).agg({'Base_Export_KG':'sum','PreDev_Export_KG':'sum','Change_Export_KG':'sum'}).reset_index()\n",
    "\n",
    "    groupedTotals = filtered.groupby(['Source Region','Constituent']).agg({'Base_Export_KG':'sum','PreDev_Export_KG':'sum','Change_Export_KG':'sum'}).reset_index()\n",
    "    \n",
    "    groupedTotals = groupedTotals.rename(columns={'Base_Export_KG':'Base_Total_KG',\n",
    "                                                  'PreDev_Export_KG':'PreDev_Total_KG','Change_Export_KG':'Change_Total_KG'})\n",
    "    \n",
    "    mergeddf = pd.merge(groupedData, groupedTotals, how='left'\n",
    "                        , left_on=['Source Region','Constituent'], right_on=['Source Region','Constituent']).reset_index()\n",
    "    \n",
    "    \n",
    "    mergeddf['BaseContribution'] = mergeddf['Base_Export_KG'] / mergeddf['Base_Total_KG'] * 100\n",
    "    mergeddf['PreDevContribution'] = mergeddf['PreDev_Export_KG'] / mergeddf['PreDev_Total_KG'] * 100\n",
    "    mergeddf['ChangeContribution'] = mergeddf['Change_Export_KG'] / mergeddf['Change_Total_KG'] * 100\n",
    "    \n",
    "#     #rawcontrib['SCENARIO'] = scenarioName\n",
    "#     rawcontrib[annLoadToStream] = rawcontrib['LoadToStream (kg)'].div(rawcontrib['Num_Days']).mul(365.25)\n",
    "#     rawcontrib[annLoadToExport] = rawcontrib['LoadToRegExport (kg)'].div(rawcontrib['Num_Days']).mul(365.25)\n",
    "#     rawcontrib['AreaHA'] = rawcontrib['AreaM2'].div(10000)\n",
    "    \n",
    "#     if regionIDString in alternativeRegionsCSV:\n",
    "#         print(\"Reading alternative regionalistaion for \" + regionIDString)\n",
    "#         altDetsDF = pd.read_csv(alternativeRegionsCSV[regionIDString])\n",
    "#         combinedDF = pd.merge(rawcontrib, altDetsDF, how='left', left_on=[origLinker], right_on = [altRegLinker])\n",
    "#         #Transfer vals\n",
    "#         combinedDF['Rep_Region'] = combinedDF[altRegColName]\n",
    "#         #Drop cols\n",
    "#         #where 1 is the axis number (0 for rows and 1 for columns.)\n",
    "#         combinedDF = combinedDF.drop(altRegColName, 1)\n",
    "#         combinedDF = combinedDF.drop(standardRegName, 1)\n",
    "#         combinedDF = combinedDF.drop(altRegLinker, 1)\n",
    "#         rawcontrib = combinedDF\n",
    "    \n",
    "#     ### Can keep reporting region in the area table, as this is our Non-Nested notebook\n",
    "#     catchFuArea = pd.DataFrame(rawcontrib.groupby(['Rep_Region','ModelElement','FU']).agg({'AreaHA':'first'})).reset_index()\n",
    "#     regFuArea = pd.DataFrame(catchFuArea.groupby(['Rep_Region','FU']).agg({'AreaHA':'sum'})).reset_index()\n",
    "    \n",
    "#     #regLuseSummary = pd.DataFrame(rawcontrib[rawcontrib['Constituent'].isin(selectedConstituents)].groupby(['Rep_Region','Constituent','FU','Process']).agg({'AnnLoadToStreamKG':'sum','AnnLoadToExportKG':'sum'})).reset_index()\n",
    "#     regLuseSummary = pd.DataFrame(rawcontrib.groupby(['SCENARIO','Rep_Region','Constituent','FU','Process']).agg({annLoadToStream:'sum',annLoadToExport:'sum'})).reset_index()\n",
    "    \n",
    "#     ### Join/merge with Regional Areas\n",
    "#     regLuseSumPlusArea = pd.merge(regLuseSummary, regFuArea, how='left', left_on=['Rep_Region','FU'], right_on = ['Rep_Region','FU'])\n",
    "    \n",
    "    mergeddf.to_csv(theFileOut, index=False)\n",
    "    \n",
    "    print(\"Saved \" + theFileOut)\n",
    "    \n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: BU\n",
      "Processing P:\\projects\\RC8_ResultsSets\\SummariesWithProcessRC10regions\\BU_RC2016_AnthroRegByLanduseProcess.csv\n",
      "Saved P:\\projects\\RC8_ResultsSets\\SummariesWithProcessRC10regions\\BU_RC2016_ProcessExportContribution.csv\n",
      "Finished first summary\n"
     ]
    }
   ],
   "source": [
    "#List out the processes\n",
    "\n",
    "for theReg in regionIDs:\n",
    "    print(\"Doing: \" + theReg)\n",
    "    produceSummaryFromProcessFile(theReg)\n",
    "\n",
    "print(\"Finished first summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
