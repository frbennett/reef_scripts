{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#elementMapperCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\CSIRO_GBR_ElementMapper.csv'\n",
    "##Names from element mapper\n",
    "regID = 'RegID'\n",
    "#riverCol = 'Major River'\n",
    "#elementCol = 'Network Element'\n",
    "\n",
    "##All sediment strategies together\n",
    "simMapperCSV = r'P:\\projects\\eReefs\\GBRF_SpeedScenarios\\GBRF_ScenarioExtension_ResultsMapperFiltered_FSED_ALL.csv'\n",
    "\n",
    "#Names from sim mapper, use RegID from above\n",
    "basinFolderName = 'BasinFolder'\n",
    "simColName = 'SIMCODE'\n",
    "#Switch these for TS Dependent or EMCMonthly\n",
    "#### ALSO 2 DIRECTORY STRUCTURE CHANGEs IN PROCESSING CELL\n",
    "existSimFolderName = 'TSDependentSubDir'\n",
    "existResultsFolderName = r'E:\\GBRFScenarios\\Results'\n",
    "#existSimFolderName = 'EMCMonthly2021SubDir'\n",
    "#existResultsFolderName = r'P:\\projects\\RC10_ResultsSets\\Models\\results'\n",
    "\n",
    "\n",
    "#outPath = r'E:\\GBRFScenarios\\SynthesisedTotalsEmpiricalEMC_DIN_RegAggregation'\n",
    "#outPath = r'E:\\GBRFScenarios\\SynthTotalsEmpiricalEMC_FSED_RegAggregationDetailed'\n",
    "outPath = r'E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed'\n",
    "#existSummariesFolderName = r'E:\\GBRFScenarios\\CSIROAggregatedOutlets\\GBRDynSedNet'\n",
    "#outPath = r'E:\\GBRFScenarios\\SynthesisedTotalsGBRDynSedNet'\n",
    "\n",
    "Constituents = ['Sediment - Fine', 'N_Particulate', 'N_DIN', 'N_DON', 'P_Particulate', 'P_DOP', 'P_FRP']\n",
    "\n",
    "\n",
    "#EMC Monthly Bases\n",
    "#regionBASEs = {'BU':'BU_RC10_BASE_GBRF_EMCMonthly_Jun2021','FI':'FI_RC10_BASE_EMCMonthly_Jun2021',\n",
    "#               'WT':'WT_RC10_BASE_GBRF_EMCMonthly_Jun2021','BM':'BM_RC10_BASE_EMCMonthly_Jun2021'}\n",
    "\n",
    "#TS Dependent Bases\n",
    "regionBASEs = {'BU':'BU_RC10_BASE_GBRF_2017','FI':'FI_RC10_BASE_2018',\n",
    "               'WT':'WT_RC10_BASE_GBRF_2018','BM':'BM_RC10_BASE_2018'}\n",
    "\n",
    "regionIDs = {'BM':'Burnett Mary Rebuild 2014','BU':'Burdekin Rebuild 2014','FI':'FI RC2019',\n",
    "              'MW':'MW_RC10', 'WT':'WT_RC10', 'CY':'CY Rebuild 2015'}\n",
    "\n",
    "regionBasins = {'BM':'BurnettMary', 'BU':'Burdekin', 'FI':'Fitzroy', 'MW':'MackayWhitsundays', 'WT':'WetTropics'}\n",
    "\n",
    "\n",
    "scenariosForReg = {'BU':['BURFSEDALL'], 'WT':['WTFSEDALL'], 'FI':['FIFSEDALL'], 'BM':['BMFSEDALL']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made dir: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outPath):\n",
    "    os.makedirs(outPath)\n",
    "    print(\"Made dir: \" + outPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allElementsTable = pd.read_csv(elementMapperCSV)\n",
    "simDetailsDF = pd.read_csv(simMapperCSV)\n",
    "for col in simDetailsDF.columns:\n",
    "    simDetailsDF[col] = simDetailsDF[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getResultsPathInfo(regionIDString, scenarioString):\n",
    "#     tsPath = existSummariesFolderName + '\\\\' + regionBasins[regionIDString] + '\\\\' + scenarioString + '\\\\Regional_TimeSeries\\\\Aggregated'\n",
    "# #     if addRegIdDIR:\n",
    "# #         tsPath = parentResultsDir + '\\\\' + regionIDString + '\\\\' + regionIDs[regionIDString] + '\\\\' + scenarioString + '\\\\TimeSeries'\n",
    "# #     else:\n",
    "# #         tsPath = parentResultsDir + '\\\\' + regionIDs[regionIDString] + '\\\\' + scenarioString + '\\\\TimeSeries'\n",
    "#     return tsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSynthesisedTotalsTS(thisRegID, theseSims):\n",
    "    \n",
    "    #grab baseline totals\n",
    "    #EMC Monthly Structure\n",
    "    #theBaseDIR = existResultsFolderName + '\\\\' + regionIDs[thisRegID] + '\\\\' + regionBASEs[thisRegID] + '\\\\Regional_TimeSeries\\\\Aggregated'\n",
    "    #TimeSeries Structure\n",
    "    theBaseDIR = existResultsFolderName + '\\\\' + thisRegID + '\\\\' + regionIDs[thisRegID] + '\\\\' + regionBASEs[thisRegID] + '\\\\Regional_TimeSeries\\\\Aggregated'\n",
    "\n",
    "    allTotals = {}\n",
    "    riverBasedMerged = {}\n",
    "    baseCols = []\n",
    "    dateList = []\n",
    "    riversList = []\n",
    "    counter = 0\n",
    "    for fname in os.listdir(theBaseDIR):\n",
    "        if '_Aggregated_Outflow' in fname:\n",
    "            #We're grabbing this baseline data\n",
    "            riverSystemName = fname.split('_Aggregated_Outflow')[0]\n",
    "            #print(\"Base River name: \" + riverSystemName)\n",
    "            if not riverSystemName in riversList:\n",
    "                riversList.append(riverSystemName)\n",
    "                #print(\"Added River to list: \" + riverSystemName)\n",
    "                allTotals[riverSystemName] = {}\n",
    "            \n",
    "            baseFilePath = os.path.join(theBaseDIR,fname)\n",
    "            baseData = pd.read_csv(baseFilePath)\n",
    "            for col in baseData.columns:\n",
    "                if not col == 'Date':\n",
    "                    baseData[col] = baseData[col].astype(float)\n",
    "            baseCols = baseData.columns.tolist()\n",
    "            #print(\"Base Cols: \" + str(baseCols))\n",
    "            allTotals[riverSystemName]['BASE'] = baseData.copy()\n",
    "            allTotals[riverSystemName]['SYNTH'] = baseData.copy()#just in case....\n",
    "            riverBasedMerged[riverSystemName] = baseData.copy()\n",
    "            if counter == 0:\n",
    "                dateList = baseData['Date'].tolist()\n",
    "            counter += 1\n",
    "    \n",
    "    #print(\"Date length: \" + str(len(dateList)))\n",
    "    #print(\"Rivers: \" + str(riversList))\n",
    "    constitCols = baseCols.copy()\n",
    "    constitCols.remove('Date')\n",
    "    constitCols.remove('Flow m3_per_s')\n",
    "    #print(\"Constituent Cols: \" + str(constitCols))\n",
    "    \n",
    "    #make synthCols list, for later\n",
    "    #Use basecols... it'll make sense later\n",
    "    synthCols = []\n",
    "    for consCol in baseCols:\n",
    "        if consCol in constitCols:\n",
    "            #For detailed output\n",
    "            synthCols.append(consCol)\n",
    "            synthCols.append('Diff_' + consCol)\n",
    "            #For simple output\n",
    "            synthCols.append('Synth_' + consCol)\n",
    "            \n",
    "        else:\n",
    "            ##print(\"should be jamming this entry in here: \" + consCol)\n",
    "            #Gives Date etc\n",
    "            synthCols.append(consCol)\n",
    "    \n",
    "    #print(\"Synth Cols: \" + str(synthCols))\n",
    "    \n",
    "    simTotals = {}\n",
    "    for sim in theseSims:\n",
    "        #Get the directory associated with the sim\n",
    "        #Wet Tropics will have duplicate rows, so take the first one\n",
    "        \n",
    "        simBits = simDetailsDF.loc[(simDetailsDF[regID] == thisRegID) & (simDetailsDF[simColName] == sim)]\n",
    "#         #two step filter\n",
    "#         simBits = simDetailsDF.loc[simDetailsDF[regID] == thisRegID]\n",
    "#         #print(simBits)\n",
    "#         for col in simBits.columns:\n",
    "#             simBits[col] = simBits[col].astype(str)\n",
    "        \n",
    "#         print(simBits[simColName])\n",
    "#         simBits2 = simBits.loc[simBits[simColName] == sim] \n",
    "#         print(simBits2)\n",
    "        \n",
    "        #'Code' will be unique\n",
    "        #simBits = simDetailsDF.loc[simDetailsDF['Code'] == sim]\n",
    "        \n",
    "        #print(\"thisRegID: \" + thisRegID)\n",
    "        #print(\"sim: \" + sim)\n",
    "        #print(\"Simbits: \" + simBits)\n",
    "        #resFold = simBits[0][existSimFolderName]\n",
    "        resFold = simBits[existSimFolderName].values[0]\n",
    "        #print(\"resFold: \" + resFold)\n",
    "        print(resFold)\n",
    "        \n",
    "        \n",
    "        #EMC Monthly Structure\n",
    "        #theSimDIR = existResultsFolderName + '\\\\' + regionIDs[thisRegID] + '\\\\' + resFold  + '\\\\Regional_TimeSeries\\\\Aggregated'\n",
    "        #TimeSeries Structure\n",
    "        theSimDIR = existResultsFolderName + '\\\\' + thisRegID + '\\\\' + regionIDs[thisRegID] + '\\\\' + resFold  + '\\\\Regional_TimeSeries\\\\Aggregated'\n",
    "\n",
    "    for fname in os.listdir(theSimDIR):\n",
    "            if '_Aggregated_Outflow' in fname:\n",
    "                riverSystemName = fname.split('_Aggregated_Outflow')[0]\n",
    "                #print(\"Sim River name: \" + riverSystemName)\n",
    "                simFilePath = os.path.join(theSimDIR,fname)\n",
    "                simData = pd.read_csv(simFilePath)\n",
    "                for col in simData.columns:\n",
    "                    if not col == 'Date':\n",
    "                        simData[col] = simData[col].astype(float)\n",
    "                \n",
    "                #Remove flow form sim\n",
    "                simData.drop('Flow m3_per_s', axis=1, inplace=True)\n",
    "                \n",
    "                #rename constitCols\n",
    "                for col in constitCols:\n",
    "                    simData.rename(columns={col:sim + '_' + col}, inplace=True)\n",
    "                    #print(\"SimCols: \" + str(simData.columns))\n",
    "                                \n",
    "                allTotals[riverSystemName][sim] = simData.copy()\n",
    "                riverBasedMerged[riverSystemName] = pd.merge(riverBasedMerged[riverSystemName], simData, how='left', left_on=['Date'], right_on=['Date'])\n",
    "    \n",
    "    #Now calc differences\n",
    "    for theRiver in riversList:\n",
    "        print(\"Assessing River name: \" + theRiver)\n",
    "        \n",
    "        #Add in Diff cols for each constitent\n",
    "        for col in constitCols:\n",
    "            #riverBasedMerged[theRiver]['Diff_' + col] = 0.0\n",
    "            \n",
    "            #Build query string\n",
    "            simCount = 0\n",
    "            qryString = ''\n",
    "            qryList = []\n",
    "            for sim in theseSims:\n",
    "                if simCount == 0:\n",
    "                    qryString = sim + '_' + col\n",
    "                else:\n",
    "                    qryString = qryString + ', ' + sim + '_' + col\n",
    "                \n",
    "                simCount += 1\n",
    "                qryList.append(sim + '_' + col)\n",
    "            \n",
    "            #print(\"Qry: \" + str(qryList))\n",
    "            #sum sims\n",
    "            riverBasedMerged[theRiver]['SumSims_' + col] = riverBasedMerged[theRiver][qryList].sum(axis=1)\n",
    "            \n",
    "            #CalcDiff\n",
    "            riverBasedMerged[theRiver].loc[(riverBasedMerged[theRiver][col] * simCount) >= riverBasedMerged[theRiver]['SumSims_' + col], 'Diff_' + col] = (riverBasedMerged[theRiver][col] * simCount) - riverBasedMerged[theRiver]['SumSims_' + col]\n",
    "            riverBasedMerged[theRiver].loc[(riverBasedMerged[theRiver][col] * simCount) < riverBasedMerged[theRiver]['SumSims_' + col], 'Diff_' + col] = 0.0\n",
    "            \n",
    "            #Now synth calc\n",
    "            riverBasedMerged[theRiver]['Synth_' + col] = riverBasedMerged[theRiver][col] - riverBasedMerged[theRiver]['Diff_' + col]\n",
    "            \n",
    "        #Now remove & rename\n",
    "        ##riverBasedMerged[theRiver] = riverBasedMerged[theRiver].loc[riverBasedMerged[theRiver].columns.isin(synthCols)]\n",
    "        riverBasedMerged[theRiver] = riverBasedMerged[theRiver].filter(synthCols, axis=1)\n",
    "        \n",
    "        for consCol in constitCols:\n",
    "            #This one is we've dropped everything and want the Synth cols renamed\n",
    "            #riverBasedMerged[theRiver].rename(columns={'Synth_' + consCol:consCol}, inplace=True)\n",
    "            #This one to identify the base data\n",
    "            riverBasedMerged[theRiver].rename(columns={consCol:'Base_' + consCol}, inplace=True)\n",
    "       \n",
    "        #Now write the rivers synthesised totals???\n",
    "        outPathFileDir = outPath + '\\\\' + regionBasins[thisRegID]\n",
    "        \n",
    "        if not os.path.exists(outPathFileDir):\n",
    "            os.makedirs(outPathFileDir)\n",
    "            print(\"Made dir: \" + outPathFileDir)\n",
    "    \n",
    "        outPathFile = outPathFileDir + '\\\\' + theRiver + '_Aggregated_Outflow.csv'\n",
    "        #allTotals[theRiver]['SYNTH'].to_csv(outPathFile, index=False)\n",
    "        riverBasedMerged[theRiver].to_csv(outPathFile, index=False)\n",
    "        print(\"Written file: \" + outPathFile)\n",
    "        \n",
    "        \n",
    "    print(\"Done \" + regionBasins[thisRegID] + \" at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing this basin: BurnettMary at 2022-01-24 15:59:33.593788\n",
      "BM_GBRF_MARYRIV_STREAMBANK12p5 GRZPROPADJ_2018\n",
      "Assessing River name: Baffle\n",
      "Made dir: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\\Baffle_Aggregated_Outflow.csv\n",
      "Assessing River name: Burnett\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\\Burnett_Aggregated_Outflow.csv\n",
      "Assessing River name: Burrum\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\\Burrum_Aggregated_Outflow.csv\n",
      "Assessing River name: Kolan\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\\Kolan_Aggregated_Outflow.csv\n",
      "Assessing River name: Mary\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\BurnettMary\\Mary_Aggregated_Outflow.csv\n",
      "Done BurnettMary at 2022-01-24 15:59:36.524964\n",
      "Doing this basin: Burdekin at 2022-01-24 15:59:36.533040\n",
      "BU_GBRF_FSED_ALL_2017\n",
      "Assessing River name: Black\n",
      "Made dir: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\\Black_Aggregated_Outflow.csv\n",
      "Assessing River name: Burdekin\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\\Burdekin_Aggregated_Outflow.csv\n",
      "Assessing River name: Don\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\\Don_Aggregated_Outflow.csv\n",
      "Assessing River name: Haughton\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\\Haughton_Aggregated_Outflow.csv\n",
      "Assessing River name: Ross\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Burdekin\\Ross_Aggregated_Outflow.csv\n",
      "Done Burdekin at 2022-01-24 15:59:39.286286\n",
      "Doing this basin: Fitzroy at 2022-01-24 15:59:39.286286\n",
      "FI_GBRF_FSED_ALL_2018\n",
      "Assessing River name: Boyne\n",
      "Made dir: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Boyne_Aggregated_Outflow.csv\n",
      "Assessing River name: Calliope\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Calliope_Aggregated_Outflow.csv\n",
      "Assessing River name: Fitzroy\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Fitzroy_Aggregated_Outflow.csv\n",
      "Assessing River name: Shoalwater\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Shoalwater_Aggregated_Outflow.csv\n",
      "Assessing River name: Styx\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Styx_Aggregated_Outflow.csv\n",
      "Assessing River name: Water Park\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\Fitzroy\\Water Park_Aggregated_Outflow.csv\n",
      "Done Fitzroy at 2022-01-24 15:59:42.904924\n",
      "Doing this basin: WetTropics at 2022-01-24 15:59:42.904924\n",
      "WT_GBRF_HERB_FSED_ALL_2018\n",
      "Assessing River name: Barron\n",
      "Made dir: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Barron_Aggregated_Outflow.csv\n",
      "Assessing River name: Daintree\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Daintree_Aggregated_Outflow.csv\n",
      "Assessing River name: Herbert\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Herbert_Aggregated_Outflow.csv\n",
      "Assessing River name: Johnstone\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Johnstone_Aggregated_Outflow.csv\n",
      "Assessing River name: Mossman\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Mossman_Aggregated_Outflow.csv\n",
      "Assessing River name: Mulgrave-Russell\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Mulgrave-Russell_Aggregated_Outflow.csv\n",
      "Assessing River name: Murray\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Murray_Aggregated_Outflow.csv\n",
      "Assessing River name: Tully\n",
      "Written file: E:\\GBRFScenarios\\SynthTotalsGBRDynSedNet_FSED_RegAggregationDetailed\\WetTropics\\Tully_Aggregated_Outflow.csv\n",
      "Done WetTropics at 2022-01-24 15:59:47.559673\n",
      "All finished at 2022-01-24 15:59:47.579159\n"
     ]
    }
   ],
   "source": [
    "#This is where we will loop through sims\n",
    "for theReg in regionIDs.keys():\n",
    "    if theReg in scenariosForReg:\n",
    "        simList = scenariosForReg[theReg]\n",
    "        print(\"Doing this basin: \" + regionBasins[theReg] + \" at \" + str(datetime.datetime.now()))\n",
    "        createSynthesisedTotalsTS(theReg, simList)\n",
    "\n",
    "\n",
    "\n",
    "# for index, row in simDetailsDF.iterrows():\n",
    "#     if row[regID] in regionIDs.keys():\n",
    "#         if row[newSimFolderName] in scenariosForReg[row[regID]]:\n",
    "#             print(\"Doing this simulation: \" + row[newSimFolderName] + \" at \" + str(datetime.datetime.now()))\n",
    "#             #Filter out the river elements for this region\n",
    "#             filteredElements = allElementsTable.loc[allElementsTable[regID] == row[regID]]\n",
    "#             doThisSim(row[regID], row[basinFolderName], row[newSimFolderName], row[existSimFolderName], filteredElements)\n",
    "\n",
    "print(\"All finished at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
