{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one uses an active scenario in the GUI\n",
    "\n",
    "\n",
    "from veneer.manage import start, create_command_line, kill_all_now\n",
    "import veneer\n",
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "#from veneer.pest_runtime import *\n",
    "\n",
    "\n",
    "veneer_port = 9876\n",
    "v = veneer.Veneer(veneer_port)\n",
    "\n",
    "\n",
    "\n",
    "#nodeOfInterestName = '120212A'\n",
    "#outputCSV = 'D:/aa/testingSubCats.csv'\n",
    "#outputCSV = r'C:\\DDrive\\WetTropics\\Johnstone\\contribCatchs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/01/1970 12:00:00 AM\n",
      "30/06/2021 12:00:00 AM\n"
     ]
    }
   ],
   "source": [
    "#Check we have the right scenario\n",
    "sDate = v.model.get('scenario.CurrentConfiguration.StartDate')\n",
    "print(sDate)\n",
    "\n",
    "eDate = v.model.get('scenario.CurrentConfiguration.EndDate')\n",
    "print(eDate)\n",
    "\n",
    "#v.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "the_network = v.network()\n",
    "#outlets = the_network.outlet_nodes()\n",
    "#outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLinks(theNetwork, currentLink):\n",
    "    theLinkName = currentLink['properties']['name']\n",
    "    theLinkID = currentLink['id']\n",
    "    \n",
    "    #print(\"Now processing: \" + theLinkName)\n",
    "          \n",
    "    # I think this will actually return a catchment record, not just an ID\n",
    "    theCat = theNetwork['features'].find_by_link(theLinkID)[0]\n",
    "    \n",
    "    #print(theCat)\n",
    "    \n",
    "    thisCatName = theCat['properties']['name']\n",
    "    #print(thisCatName)\n",
    "    #thisCatArea = theCat['properties']['areaInSquareMeters']\n",
    "    \n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    \n",
    "    #print(\"Processing \" + thisCatName + \" with area of \" + str(thisCatArea))\n",
    "        \n",
    "    fNodeID = currentLink['properties']['from_node']\n",
    "    \n",
    "    #print(\"Node info: \" + fNodeID)\n",
    "    \n",
    "    fNode = the_network['features'].find_by_id(fNodeID)\n",
    "    #print(fNode)\n",
    "    \n",
    "    fNodeName = fNode[0]['properties']['name']\n",
    "    #print(fNodeName)\n",
    "    \n",
    "    ## recurse\n",
    "    #print(the_network.upstream_links(fNode[0]))\n",
    "    for upLink in the_network.upstream_links(fNode[0]):\n",
    "        #tNodeID = upLink['properties']['to_node']\n",
    "        #tNode = the_network['features'].find_by_id(tNodeID)\n",
    "        #print(\"Now processing: \" + upLink['properties']['name'] + \" upstream of \" + tNode[0]['properties']['name'] + \" with initial Region: \" + currentReg)\n",
    "        processLinks(theNetwork, upLink)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made dir: P:\\projects\\eReefsOperational\\CSIRO_Locs\\CYAreas\n",
      "Done exporting Outlet Node106\n",
      "Done exporting Outlet Node105\n",
      "Done exporting Outlet Node104\n",
      "Done exporting Outlet Node101\n",
      "Done exporting Outlet Node99\n",
      "Done exporting Outlet Node97\n",
      "Done exporting Outlet Node96\n",
      "Done exporting Outlet Node95\n",
      "Done exporting Outlet Node89\n",
      "Done exporting Outlet Node93\n",
      "Done exporting Outlet Node94\n",
      "Done exporting Outlet Node79\n",
      "Done exporting Outlet Node77\n",
      "Done exporting Outlet Node76\n",
      "Done exporting Outlet Node73\n",
      "Done exporting Outlet Node71\n",
      "Done exporting Outlet Node70\n",
      "Done exporting Outlet Node16\n",
      "Done exporting Outlet Node69\n",
      "Done exporting Outlet Node67\n",
      "Done exporting Outlet Node66\n",
      "Done exporting Outlet Node64\n",
      "Done exporting Outlet Node62\n",
      "Done exporting Outlet Node57\n",
      "Done exporting Outlet Node56\n",
      "Done exporting Outlet Node55\n",
      "Done exporting Outlet Node2\n",
      "All complete\n"
     ]
    }
   ],
   "source": [
    "#elementMapper = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\WetTropicsElementMapperAll.csv'\n",
    "#outputLoc = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\WTAreas'\n",
    "\n",
    "#elementMapper = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\MackayWhitsundayElementMapperAll.csv'\n",
    "#outputLoc = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\MWAreas'\n",
    "\n",
    "#elementMapper = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\FitzroyElementMapperAll.csv'\n",
    "#outputLoc = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\FIAreas'\n",
    "\n",
    "#elementMapper = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BurnettMaryElementMapperAll.csv'\n",
    "#outputLoc = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BMAreas'\n",
    "\n",
    "elementMapper = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\CapeYorkElementMapperAll.csv'\n",
    "outputLoc = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\CYAreas'\n",
    "\n",
    "if not os.path.exists(outputLoc):\n",
    "    os.makedirs(outputLoc)\n",
    "    print(\"Made dir: \" + outputLoc)\n",
    "\n",
    "elementMapperDF = pd.read_csv(elementMapper)\n",
    "\n",
    "for index, row in elementMapperDF.iterrows():\n",
    "    \n",
    "    GlobalCatchList = []\n",
    "    \n",
    "    elementOfInterestName = row['Network Element']\n",
    "    elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "    \n",
    "    outputCSV = os.path.join(outputLoc,elementOfInterestName + \".csv\")\n",
    "    \n",
    "    if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "        #Need to add the link/catchent to our collection\n",
    "        theLinkID = elementOfInterest[0]['id']\n",
    "        theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "        thisCatName = theCat['properties']['name']\n",
    "        GlobalCatchList.append(thisCatName)\n",
    "        print(\"Added our starting link first\")\n",
    "    \n",
    "    #print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "    ## now we begin processing\n",
    "    for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "        #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "        processLinks(the_network, upLink)\n",
    "\n",
    "    contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "    #contCatchsDF\n",
    "    contCatchsDF.to_csv(outputCSV, index=False)\n",
    "    print(\"Done exporting \" + elementOfInterestName)\n",
    "\n",
    "    \n",
    "    \n",
    "print(\"All complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #1643'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_DonRiver.csv'\n",
    "\n",
    "\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #1655'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_EuriCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node12'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_CrocodileCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node11'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_AlligatorCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node9'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_RossRiver.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node8'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_BohleRiver.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = '117002a'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_BlackRiver.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node6'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_AlthousCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = '117003a'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_BluewaterCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node14'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_BarramundiCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node28'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_ElliotRiver.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node27'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_CapeCreekr.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node26'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_SandyCreek.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node21'\n",
    "outputCSV = r'P:\\projects\\eReefsOperational\\CSIRO_Locs\\BUAreas\\contribCatchs_BurdekinRiver.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #325'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_UpperBurnett.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #107'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_BarkerBarambah.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #244'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_AuburnBoyne1.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #178'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_AuburnBoyne2.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added our starting link first\n",
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'link for catchment SC #501'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_UpperMary.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node18'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_NorthBurrum.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node19'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_SouthBurrum.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node16'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_SouthElliott.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node14'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_NorthElliott.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done exporting\n"
     ]
    }
   ],
   "source": [
    "GlobalCatchList = []\n",
    "\n",
    "elementOfInterestName = 'Outlet Node20'\n",
    "outputCSV = r'E:\\BurnettMaryRC11\\contribCatchs_HerveyBay.csv'\n",
    "\n",
    "elementOfInterest = the_network['features'].find_by_name(elementOfInterestName)\n",
    "\n",
    "#print(elementOfInterest[0]['properties']['feature_type'])\n",
    "\n",
    "if elementOfInterest[0]['properties']['feature_type'] == 'link':\n",
    "    #Need to add the link/catchent to our collection\n",
    "    theLinkID = elementOfInterest[0]['id']\n",
    "    theCat = the_network['features'].find_by_link(theLinkID)[0]\n",
    "    thisCatName = theCat['properties']['name']\n",
    "    GlobalCatchList.append(thisCatName)\n",
    "    print(\"Added our starting link first\")\n",
    "\n",
    "#print(\"NOF: \" + nodeOfInterest[0]['properties']['name'])\n",
    "## now we begin processing\n",
    "for upLink in the_network.upstream_links(elementOfInterest[0]):\n",
    "    #print(\"Recursing for link: \" + upLink['properties']['name'])\n",
    "    processLinks(the_network, upLink)\n",
    "\n",
    "contCatchsDF = pd.DataFrame(GlobalCatchList, columns=['SubCats'])\n",
    "#contCatchsDF\n",
    "contCatchsDF.to_csv(outputCSV, index=False)\n",
    "print(\"Done exporting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
