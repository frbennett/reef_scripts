{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from sklearn import metrics  \n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from itertools import combinations \n",
    "import pandasql as psql\n",
    "import glob\n",
    "import os\n",
    "import fnmatch\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"C:/Users/bennettf/Desktop/New folder (7)/APSIMsims/\"\n",
    "#path = \"D:/Burdekin/apsim_stuff/APSIMsims/\"\n",
    "#path = \"D:/Burdekin/apsim_stuff/corr/csvs/\"\n",
    "path = \"R:/ReefSugar_RC7/BU/BU_RatoonAggregated_NoTotals/\"\n",
    "#path = \"R:/ReefSugar_RC7/BU/smallSet/\"\n",
    "outpath = \"R:/ReefSugar_RC7/BU/clusters_din/\"\n",
    "#column_name = \"Nleached\"\n",
    "#column_names = ['Runoff','soil_loss2','Grants_DINrunoff','Nleached']\n",
    "column_names = ['Grants_DINrunoff','Nleached']\n",
    "extens = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding combo: coom_1955_14710_adj\n",
      "Adding combo: coom_1970_14735_adj\n",
      "Adding combo: coom_1975_14710_adj\n",
      "Adding combo: coom_2010_14725_adj\n",
      "Adding combo: garb_1955_14710_adj\n",
      "Adding combo: garb_1970_14735_adj\n",
      "Adding combo: garb_1975_14710_adj\n",
      "Adding combo: garb_2005_14815_adj\n",
      "Adding combo: garb_2010_14725_adj\n",
      "Adding combo: hatc_1955_14710_adj\n",
      "Adding combo: hatc_1970_14735_adj\n",
      "Adding combo: hatc_1975_14710_adj\n",
      "Adding combo: hatc_2005_14815_adj\n",
      "Adding combo: hatc_2010_14725_adj\n",
      "Adding combo: kala_1955_14710_adj\n",
      "Adding combo: kala_1970_14735_adj\n",
      "Adding combo: kala_1975_14710_adj\n",
      "Adding combo: mari_1955_14710_adj\n",
      "Adding combo: mari_1970_14735_adj\n",
      "Adding combo: mari_1975_14710_adj\n",
      "Adding combo: mari_2005_14815_adj\n",
      "Adding combo: mari_2010_14725_adj\n",
      "Adding combo: neil_1955_14710_adj\n",
      "Adding combo: neil_1970_14735_adj\n",
      "Adding combo: neil_1975_14710_adj\n",
      "Adding combo: neil_2010_14725_adj\n"
     ]
    }
   ],
   "source": [
    "#data_set = pd.DataFrame()\n",
    "\n",
    "dataframe_collection = {}\n",
    "encounteredCombos = []\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "    \n",
    "file_list = fnmatch.filter(os.listdir(path), '*' + extens)\n",
    "\n",
    "#Parallel(n_jobs=num_cores)(for file in file_list):\n",
    "for file in file_list :\n",
    "    # compose a column heading name from the filename\n",
    "    #file_split = file.split('_')\n",
    "    #coom$1955_14710_adj$bpafaf$irra.csv\n",
    "    #print('Processing file: ' + file)\n",
    "    file_split = file.replace(extens, '').split('$')\n",
    "    soil = file_split[0]\n",
    "    climate = file_split[1]\n",
    "    #ks = file_split[7].split(' ')[0]\n",
    "    mgt1 = file_split[2]\n",
    "    irrig = file_split[3]\n",
    "    mgt = mgt1 + '_' + irrig\n",
    "    #baseCombo = soil + '_' + climate + '_' + irrig\n",
    "    baseCombo = soil + '_' + climate\n",
    "    #heading = mgt\n",
    "    \n",
    "    if baseCombo not in encounteredCombos:\n",
    "        encounteredCombos.append(baseCombo)\n",
    "        print('Adding combo: ' + baseCombo)\n",
    "        dataframe_collection[baseCombo] = {}\n",
    "        \n",
    "        for colName in column_names:\n",
    "            dataframe_collection[baseCombo][colName] = pd.DataFrame()\n",
    "    \n",
    "    file_in = pd.read_csv(path + file, skiprows=[1])\n",
    "    #print('Reading file: ' + file)\n",
    "    \n",
    "    for colName in column_names:\n",
    "        dataframe_collection[baseCombo][colName][mgt] = file_in[colName]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for baseCombo in encounteredCombos:\n",
    "    #here\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    for colName in column_names:\n",
    "        #here\n",
    "        data_matrix = dataframe_collection[baseCombo][colName].T.as_matrix()\n",
    "        distance_matrix = dist.pdist(data_matrix, 'euclidean' )\n",
    "        Z = hac.linkage(distance_matrix, method='ward', metric='euclidean')\n",
    "        T = hac.fcluster(Z, 12, criterion='maxclust')\n",
    "        \n",
    "        if counter == 1:\n",
    "            #grab the mgt codes as a column\n",
    "            results['mgt'] = list(dataframe_collection[baseCombo][colName].columns.values)\n",
    "        \n",
    "        results[colName] = T\n",
    "        counter += 1\n",
    "        \n",
    "    #write out stuff\n",
    "    results.to_csv(outpath + baseCombo + '_MaxClust12.csv')\n",
    "\n",
    "\n",
    "\n",
    "#data_matrix = data_set.T.as_matrix()\n",
    "##distance_matrix = dist.squareform(dist.pdist(data_matrix, 'euclidean' ))\n",
    "#distance_matrix = dist.pdist(data_matrix, 'euclidean' )\n",
    "#Z = hac.linkage(distance_matrix, method='ward', metric='euclidean')\n",
    "#fig = plt.figure(figsize=(25, 10))\n",
    "#plt.title('Hierarchical Clustering Dendrogram')\n",
    "#plt.xlabel('sample index')\n",
    "#plt.ylabel('distance')\n",
    "#dn = dendrogram(Z)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
