{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from sklearn import metrics  \n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from itertools import combinations \n",
    "import pandasql as psql\n",
    "import glob\n",
    "import os\n",
    "import fnmatch\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.optimize import minimize, rosen, rosen_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"C:/Users/bennettf/Desktop/New folder (7)/APSIMsims/\"\n",
    "#path = \"D:/Burdekin/apsim_stuff/APSIMsims/\"\n",
    "#path = \"D:/Burdekin/apsim_stuff/corr/csvs/\"\n",
    "path = \"R:/ReefSugar_RC7/BU/BU_RatoonAggregated_NoTotals/\"\n",
    "#path = \"R:/ReefSugar_RC7/BU/smallSet/\"\n",
    "outpath = \"R:/ReefSugar_RC7/BU/clusters/\"\n",
    "#column_name = \"Nleached\"\n",
    "column_names = ['Runoff','soil_loss2','Grants_DINrunoff','Nleached']\n",
    "extens = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding combo: coom_1955_14710_adj_irra\n",
      "Adding combo: coom_1955_14710_adj_irrb\n",
      "Adding combo: coom_1955_14710_adj_irrc\n",
      "Adding combo: coom_1955_14710_adj_irrd\n",
      "Adding combo: coom_1970_14735_adj_irra\n",
      "Adding combo: coom_1970_14735_adj_irrb\n",
      "Adding combo: coom_1970_14735_adj_irrc\n",
      "Adding combo: coom_1970_14735_adj_irrd\n",
      "Adding combo: coom_1975_14710_adj_irra\n",
      "Adding combo: coom_1975_14710_adj_irrb\n",
      "Adding combo: coom_1975_14710_adj_irrc\n",
      "Adding combo: coom_1975_14710_adj_irrd\n",
      "Adding combo: coom_2010_14725_adj_irra\n",
      "Adding combo: coom_2010_14725_adj_irrb\n",
      "Adding combo: coom_2010_14725_adj_irrc\n",
      "Adding combo: coom_2010_14725_adj_irrd\n",
      "Adding combo: garb_1955_14710_adj_irra\n",
      "Adding combo: garb_1955_14710_adj_irrb\n",
      "Adding combo: garb_1955_14710_adj_irrc\n",
      "Adding combo: garb_1955_14710_adj_irrd\n",
      "Adding combo: garb_1970_14735_adj_irra\n",
      "Adding combo: garb_1970_14735_adj_irrb\n",
      "Adding combo: garb_1970_14735_adj_irrc\n",
      "Adding combo: garb_1970_14735_adj_irrd\n",
      "Adding combo: garb_1975_14710_adj_irra\n",
      "Adding combo: garb_1975_14710_adj_irrb\n",
      "Adding combo: garb_1975_14710_adj_irrc\n",
      "Adding combo: garb_1975_14710_adj_irrd\n",
      "Adding combo: garb_2005_14815_adj_irra\n",
      "Adding combo: garb_2005_14815_adj_irrb\n",
      "Adding combo: garb_2005_14815_adj_irrc\n",
      "Adding combo: garb_2005_14815_adj_irrd\n",
      "Adding combo: garb_2010_14725_adj_irra\n",
      "Adding combo: garb_2010_14725_adj_irrb\n",
      "Adding combo: garb_2010_14725_adj_irrc\n",
      "Adding combo: garb_2010_14725_adj_irrd\n",
      "Adding combo: hatc_1955_14710_adj_irra\n",
      "Adding combo: hatc_1955_14710_adj_irrb\n",
      "Adding combo: hatc_1955_14710_adj_irrc\n",
      "Adding combo: hatc_1955_14710_adj_irrd\n",
      "Adding combo: hatc_1970_14735_adj_irra\n",
      "Adding combo: hatc_1970_14735_adj_irrb\n",
      "Adding combo: hatc_1970_14735_adj_irrc\n",
      "Adding combo: hatc_1970_14735_adj_irrd\n",
      "Adding combo: hatc_1975_14710_adj_irra\n",
      "Adding combo: hatc_1975_14710_adj_irrb\n",
      "Adding combo: hatc_1975_14710_adj_irrc\n",
      "Adding combo: hatc_1975_14710_adj_irrd\n",
      "Adding combo: hatc_2005_14815_adj_irra\n",
      "Adding combo: hatc_2005_14815_adj_irrb\n",
      "Adding combo: hatc_2005_14815_adj_irrc\n",
      "Adding combo: hatc_2005_14815_adj_irrd\n",
      "Adding combo: hatc_2010_14725_adj_irra\n",
      "Adding combo: hatc_2010_14725_adj_irrb\n",
      "Adding combo: hatc_2010_14725_adj_irrc\n",
      "Adding combo: hatc_2010_14725_adj_irrd\n",
      "Adding combo: kala_1955_14710_adj_irra\n",
      "Adding combo: kala_1955_14710_adj_irrb\n",
      "Adding combo: kala_1955_14710_adj_irrc\n",
      "Adding combo: kala_1955_14710_adj_irrd\n",
      "Adding combo: kala_1970_14735_adj_irra\n",
      "Adding combo: kala_1970_14735_adj_irrb\n",
      "Adding combo: kala_1970_14735_adj_irrc\n",
      "Adding combo: kala_1970_14735_adj_irrd\n",
      "Adding combo: kala_1975_14710_adj_irra\n",
      "Adding combo: kala_1975_14710_adj_irrb\n",
      "Adding combo: kala_1975_14710_adj_irrc\n",
      "Adding combo: kala_1975_14710_adj_irrd\n",
      "Adding combo: mari_1955_14710_adj_irra\n",
      "Adding combo: mari_1955_14710_adj_irrb\n",
      "Adding combo: mari_1955_14710_adj_irrc\n",
      "Adding combo: mari_1955_14710_adj_irrd\n",
      "Adding combo: mari_1970_14735_adj_irra\n",
      "Adding combo: mari_1970_14735_adj_irrb\n",
      "Adding combo: mari_1970_14735_adj_irrc\n",
      "Adding combo: mari_1970_14735_adj_irrd\n",
      "Adding combo: mari_1975_14710_adj_irra\n",
      "Adding combo: mari_1975_14710_adj_irrb\n",
      "Adding combo: mari_1975_14710_adj_irrc\n",
      "Adding combo: mari_1975_14710_adj_irrd\n",
      "Adding combo: mari_2005_14815_adj_irra\n",
      "Adding combo: mari_2005_14815_adj_irrb\n",
      "Adding combo: mari_2005_14815_adj_irrc\n",
      "Adding combo: mari_2005_14815_adj_irrd\n",
      "Adding combo: mari_2010_14725_adj_irra\n",
      "Adding combo: mari_2010_14725_adj_irrb\n",
      "Adding combo: mari_2010_14725_adj_irrc\n",
      "Adding combo: mari_2010_14725_adj_irrd\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e888e825d0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfile_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msoil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_split\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mclimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_split\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[1;31m#ks = file_split[7].split(' ')[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_split\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#data_set = pd.DataFrame()\n",
    "\n",
    "dataframe_collection = {}\n",
    "encounteredCombos = []\n",
    "\n",
    "file_list = fnmatch.filter(os.listdir(path), '*' + extens)\n",
    "for file in file_list :\n",
    "    # compose a column heading name from the filename\n",
    "    #file_split = file.split('_')\n",
    "    #coom$1955_14710_adj$bpafaf$irra.csv\n",
    "    #print('Processing file: ' + file)\n",
    "    file_split = file.replace(extens, '').split('$')\n",
    "    soil = file_split[0]\n",
    "    climate = file_split[1]\n",
    "    #ks = file_split[7].split(' ')[0]\n",
    "    mgt = file_split[2]\n",
    "    irrig = file_split[3]\n",
    "    baseCombo = soil + '_' + climate + '_' + irrig\n",
    "    #heading = mgt\n",
    "    \n",
    "    if baseCombo not in encounteredCombos:\n",
    "        encounteredCombos.append(baseCombo)\n",
    "        print('Adding combo: ' + baseCombo)\n",
    "        dataframe_collection[baseCombo] = {}\n",
    "        \n",
    "        for colName in column_names:\n",
    "            dataframe_collection[baseCombo][colName] = pd.DataFrame()\n",
    "    \n",
    "    file_in = pd.read_csv(path + file, skiprows=[1])\n",
    "    #print('Reading file: ' + file)\n",
    "    \n",
    "    for colName in column_names:\n",
    "        dataframe_collection[baseCombo][colName][mgt] = file_in[colName]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for baseCombo in encounteredCombos:\n",
    "    #here\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    for colName in column_names:\n",
    "        #here\n",
    "        data_matrix = dataframe_collection[baseCombo][colName].T.as_matrix()\n",
    "        distance_matrix = dist.pdist(data_matrix, 'euclidean' )\n",
    "        Z = hac.linkage(distance_matrix, method='ward', metric='euclidean')\n",
    "        T = hac.fcluster(Z, 20, criterion='maxclust')\n",
    "        \n",
    "        if counter == 1:\n",
    "            #grab the mgt codes as a column\n",
    "            results['mgt'] = list(dataframe_collection[baseCombo][colName].columns.values)\n",
    "        \n",
    "        results[colName] = T\n",
    "        counter += 1\n",
    "        \n",
    "    #write out stuff\n",
    "    results.to_csv(outpath + baseCombo + '_MaxClust20.csv')\n",
    "\n",
    "\n",
    "\n",
    "#data_matrix = data_set.T.as_matrix()\n",
    "##distance_matrix = dist.squareform(dist.pdist(data_matrix, 'euclidean' ))\n",
    "#distance_matrix = dist.pdist(data_matrix, 'euclidean' )\n",
    "#Z = hac.linkage(distance_matrix, method='ward', metric='euclidean')\n",
    "#fig = plt.figure(figsize=(25, 10))\n",
    "#plt.title('Hierarchical Clustering Dendrogram')\n",
    "#plt.xlabel('sample index')\n",
    "#plt.ylabel('distance')\n",
    "#dn = dendrogram(Z)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
