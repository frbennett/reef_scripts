{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "import glob\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterpath = \"R:/ReefSugar_RC7/BU/clusters_din/\"\n",
    "#clusterpath = \"R:/ReefSugar_RC7/BU/clustersSmall/\"\n",
    "outpath = \"R:/ReefSugar_RC7/BU/clusterSummaries_din/\"\n",
    "#column_names = ['Runoff','soil_loss2','Grants_DINrunoff','Nleached']\n",
    "column_names = ['Grants_DINrunoff','Nleached']\n",
    "extens = '.csv'\n",
    "targetString = 'MaxClust12'\n",
    "#colOfInterest = 'soil_loss2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing constituent: Grants_DINrunoff\n",
      "Now file: coom_1955_14710_adj_MaxClust12.csv\n",
      "Now file: coom_1970_14735_adj_MaxClust12.csv\n",
      "Now file: coom_1975_14710_adj_MaxClust12.csv\n",
      "Now file: coom_2010_14725_adj_MaxClust12.csv\n",
      "Now file: garb_1955_14710_adj_MaxClust12.csv\n",
      "Now file: garb_1970_14735_adj_MaxClust12.csv\n",
      "Now file: garb_1975_14710_adj_MaxClust12.csv\n",
      "Now file: garb_2005_14815_adj_MaxClust12.csv\n",
      "Now file: garb_2010_14725_adj_MaxClust12.csv\n",
      "Now file: hatc_1955_14710_adj_MaxClust12.csv\n",
      "Now file: hatc_1970_14735_adj_MaxClust12.csv\n",
      "Now file: hatc_1975_14710_adj_MaxClust12.csv\n",
      "Now file: hatc_2005_14815_adj_MaxClust12.csv\n",
      "Now file: hatc_2010_14725_adj_MaxClust12.csv\n",
      "Now file: kala_1955_14710_adj_MaxClust12.csv\n",
      "Now file: kala_1970_14735_adj_MaxClust12.csv\n",
      "Now file: kala_1975_14710_adj_MaxClust12.csv\n",
      "Now file: mari_1955_14710_adj_MaxClust12.csv\n",
      "Now file: mari_1970_14735_adj_MaxClust12.csv\n",
      "Now file: mari_1975_14710_adj_MaxClust12.csv\n",
      "Now file: mari_2005_14815_adj_MaxClust12.csv\n",
      "Now file: mari_2010_14725_adj_MaxClust12.csv\n",
      "Now file: neil_1955_14710_adj_MaxClust12.csv\n",
      "Now file: neil_1970_14735_adj_MaxClust12.csv\n",
      "Now file: neil_1975_14710_adj_MaxClust12.csv\n",
      "Now file: neil_2010_14725_adj_MaxClust12.csv\n",
      "Doing constituent: Nleached\n",
      "Now file: coom_1955_14710_adj_MaxClust12.csv\n",
      "Now file: coom_1970_14735_adj_MaxClust12.csv\n",
      "Now file: coom_1975_14710_adj_MaxClust12.csv\n",
      "Now file: coom_2010_14725_adj_MaxClust12.csv\n",
      "Now file: garb_1955_14710_adj_MaxClust12.csv\n",
      "Now file: garb_1970_14735_adj_MaxClust12.csv\n",
      "Now file: garb_1975_14710_adj_MaxClust12.csv\n",
      "Now file: garb_2005_14815_adj_MaxClust12.csv\n",
      "Now file: garb_2010_14725_adj_MaxClust12.csv\n",
      "Now file: hatc_1955_14710_adj_MaxClust12.csv\n",
      "Now file: hatc_1970_14735_adj_MaxClust12.csv\n",
      "Now file: hatc_1975_14710_adj_MaxClust12.csv\n",
      "Now file: hatc_2005_14815_adj_MaxClust12.csv\n",
      "Now file: hatc_2010_14725_adj_MaxClust12.csv\n",
      "Now file: kala_1955_14710_adj_MaxClust12.csv\n",
      "Now file: kala_1970_14735_adj_MaxClust12.csv\n",
      "Now file: kala_1975_14710_adj_MaxClust12.csv\n",
      "Now file: mari_1955_14710_adj_MaxClust12.csv\n",
      "Now file: mari_1970_14735_adj_MaxClust12.csv\n",
      "Now file: mari_1975_14710_adj_MaxClust12.csv\n",
      "Now file: mari_2005_14815_adj_MaxClust12.csv\n",
      "Now file: mari_2010_14725_adj_MaxClust12.csv\n",
      "Now file: neil_1955_14710_adj_MaxClust12.csv\n",
      "Now file: neil_1970_14735_adj_MaxClust12.csv\n",
      "Now file: neil_1975_14710_adj_MaxClust12.csv\n",
      "Now file: neil_2010_14725_adj_MaxClust12.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for colOfInterest in column_names:\n",
    "    \n",
    "    print(\"Doing constituent: \" + colOfInterest)\n",
    "\n",
    "    allMgts = []\n",
    "\n",
    "    #declare this outside of loop?\n",
    "    #Phucking dataframes are hard to update individual cells, so I'll nest the shit out of some dictionaries\n",
    "    #dataMatrix = pd.DataFrame()\n",
    "    dataMatrix = {}\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    file_list = fnmatch.filter(os.listdir(clusterpath), '*' + targetString + extens)\n",
    "\n",
    "\n",
    "    for file in file_list :\n",
    "\n",
    "\n",
    "        #This should keep column names???\n",
    "        print('Now file: ' + file)\n",
    "        file_in = pd.read_csv(clusterpath + file)#, skiprows=[1]\n",
    "\n",
    "        file_in.sort_values(by='mgt')\n",
    "\n",
    "        if counter == 0:\n",
    "            #grab all mgts\n",
    "            #print(file_in['mgt'])\n",
    "            allMgts = file_in['mgt'].tolist()\n",
    "            allMgts.sort()\n",
    "            dataMatrix['mgtRows'] = file_in['mgt']\n",
    "            #Add columns\n",
    "            for availMgt in allMgts:\n",
    "\n",
    "                dataMatrix[availMgt] = {}\n",
    "\n",
    "                for avMgt2 in allMgts:\n",
    "                    #dataMatrix[availMgt].update({avMgt2, 0})\n",
    "                    dataMatrix[availMgt][avMgt2] = 0\n",
    "\n",
    "            #dataMatrix.index = 'mgtRows'\n",
    "            #print(allMgts)\n",
    "            #print(dataMatrix)\n",
    "            #for theMgt in allMgts:\n",
    "            #    print(\"Orig order \" + theMgt)\n",
    "\n",
    "\n",
    "        #Now do the processing\n",
    "        #We'll progressively drop out mgt codes here, otherwise we effectively double dip...\n",
    "        #Important this is a copy of the list, or else we're modifying the same list!\n",
    "        localListOfMgts = allMgts.copy()\n",
    "\n",
    "        #Make a dictionary lookup\n",
    "        relevantGroups = {}\n",
    "        for index, row in file_in.iterrows():\n",
    "            relevantGroups[row['mgt']] = row[colOfInterest]\n",
    "\n",
    "        #relevantGroupsKeys = sorted(relevantGroups)\n",
    "        #print(allMgts)\n",
    "        #print(file_in['mgt'])\n",
    "        #print(relevantGroupsKeys)\n",
    "\n",
    "        #Now compare\n",
    "        for theMgt in allMgts:\n",
    "\n",
    "            #print('Doing:' + theMgt)\n",
    "            currentGroup = relevantGroups[theMgt]\n",
    "\n",
    "            localListOfMgts.remove(theMgt)\n",
    "            #print('Just removed:' + theMgt)\n",
    "\n",
    "            #print(allMgts)\n",
    "\n",
    "            for otherMgt in localListOfMgts:\n",
    "                #print('OthMGT:' + otherMgt)\n",
    "                if relevantGroups[otherMgt] == currentGroup:\n",
    "\n",
    "                    #print('getting Index for ' + theMgt + ' where other Mgt is : ' + otherMgt + ' and currentGroup is: ' + str(currentGroup))\n",
    "\n",
    "                    curVal = dataMatrix[theMgt][otherMgt]\n",
    "                    #print('Here is the current ' + str(curVal))\n",
    "\n",
    "                    dataMatrix[theMgt][otherMgt] += 1\n",
    "\n",
    "                    #print('Here is the new  ' + str(dataMatrix[theMgt][otherMgt]))\n",
    "\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    #now to get into a dataframe\n",
    "    outDF = pd.DataFrame()\n",
    "\n",
    "    outDF['mgtCodes'] = allMgts\n",
    "\n",
    "    #Populate with cols and zero values\n",
    "    for theMgt in allMgts:\n",
    "        #print('adding col: ' + theMgt)\n",
    "        outDF[theMgt] = 0\n",
    "\n",
    "\n",
    "    for rowIdx, row in outDF.iterrows():\n",
    "        theMgtKey = row['mgtCodes']\n",
    "\n",
    "        #print('rowIdx: ' + (str(rowIdx)))\n",
    "\n",
    "        colIdx = 0\n",
    "        for theCol in allMgts:\n",
    "\n",
    "            if theCol != theMgtKey:\n",
    "\n",
    "                theVal = dataMatrix[theMgtKey][theCol]\n",
    "\n",
    "                #print('Value: ' + str(theVal))\n",
    "\n",
    "                #row[theCol] = theVal\n",
    "                #outDF.at[colIdx, rowIdx] = theVal\n",
    "                outDF.at[rowIdx, theCol] = theVal\n",
    "\n",
    "            colIdx += 1\n",
    "\n",
    "    outDF.to_csv(outpath + colOfInterest + '_MaxSum12.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataMatrix['afafaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataMatrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#outDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
