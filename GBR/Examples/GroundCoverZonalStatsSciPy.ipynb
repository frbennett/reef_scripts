{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Hoping to remove reliance on ArcGIS for ground cover processing\n",
    "\n",
    "# This tool will not ensure that pixels and boundaries align\n",
    "# That is the job of the user\n",
    "import pandas\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from osgeo import gdal, gdalconst\n",
    "from osgeo import ogr\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('../Modules')\n",
    "import zonalMeanByBincount\n",
    "import os\n",
    "import datetime\n",
    "import calendar\n",
    "#import scipy\n",
    "#from scipy import ndimage\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#requiredStartDate = datetime.date(1990,1,1)\n",
    "#requiredEndDate = datetime.date(1992,12,31)\n",
    "\n",
    "#Path to shapefile to use for clip/mask\n",
    "#pathToShapefile = 'D:/FractionalCover/MackayWhit_Buffer_10km_Albers.shp'\n",
    "#pathToShapefile = 'D:/FractionalCover/MaryBurnett_Buffer_10km_Albers.shp'\n",
    "\n",
    "pathToZonesRaster = 'D:/BurnettMary/spatial_RC8/BM_CreatedSubcats.asc'\n",
    "pathToZonesCategories = 'D:/BurnettMary/spatial_RC8/BM_CreatedSubcats_categories.csv'\n",
    "\n",
    "tempRasterPath = os.path.join(tempfile.gettempdir(), \"resampledData.tif\")\n",
    "\n",
    "#Do one raster only for now\n",
    "#rasterPathName = 'D:/FractionalCover/GroundCover/lztmre_qld_m198909198911_dixa2.tif'\n",
    "#Do one raster only for now\n",
    "#patchPathName = 'D:/FractionalCover/Patches/lztmre_rreef_m198909198911_dj4a2.tif'\n",
    "\n",
    "#fractionalCoverDir = r'\\\\nrm02002\\EXCHANGE\\Fractional Ground Cover\\Ground Cover'\n",
    "#patchDir = r'\\\\nrm02002\\EXCHANGE\\Fractional Ground Cover\\Ground Cover Patch'\n",
    "fractionalCoverDir = r'D:\\FractionalCover\\GroundCover'\n",
    "patchDir = r'D:\\FractionalCover\\Patches'\n",
    "\n",
    "outputDir = r'D:\\BurnettMary\\Covers'\n",
    "#outputCSV = r'D:\\BurnettMary\\Covers\\FullCoverMeans.csv'\n",
    "outputCSV = r'D:\\BurnettMary\\Covers\\TestCoverMeans.csv'\n",
    "\n",
    "requiredStartDate = datetime.date(1989,9,1)\n",
    "requiredEndDate = datetime.date(1990,5,31)\n",
    "#requiredStartDate = datetime.date(1987,9,1)\n",
    "#requiredEndDate = datetime.date(2017,2,28)\n",
    "\n",
    "#Use these to control the saved files\n",
    "saveCover = False\n",
    "#saveCFact = True\n",
    "\n",
    "extensions = ('*.tif', '*.tiff') # the tuple of file types\n",
    "\n",
    "availCoverRasters = []\n",
    "availPatchRasters = []\n",
    "\n",
    "for theExt in extensions:\n",
    "    ###\n",
    "    availCoverRasters.extend(glob.glob(fractionalCoverDir + \"/\" + theExt))\n",
    "    availPatchRasters.extend(glob.glob(patchDir + \"/\" + theExt))\n",
    "\n",
    "#availCoverRasters = glob.glob(fractionalCoverDir + \"/*.tif\")\n",
    "#availPatchRasters = glob.glob(patchDir)\n",
    "\n",
    "#Final NoData Val: can't use 0, as that is a 'valid' cover val....\n",
    "ourNoData = 240\n",
    "\n",
    "#some data storage bits and pieces\n",
    "allStats = {}\n",
    "catchIDs = {}\n",
    "foundStartDates = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the zones raster\n",
    "zoneRas = gdal.Open(pathToZonesRaster)\n",
    "zone_GeoTrans = zoneRas.GetGeoTransform()\n",
    "zonesRasterArray = zoneRas.ReadAsArray()\n",
    "ZoneNoDataVal = zoneRas.GetRasterBand(1).GetNoDataValue()\n",
    "uniqZones = np.unique(zonesRasterArray)\n",
    "### Going to give up on masking zones, as the bincount unique stuff will include it the NoData Val labels anyway\n",
    "\n",
    "\n",
    "#MaskedZones = np.ma.masked_where(zonesRasterArray==ZoneNoDataVal, zonesRasterArray)\n",
    "#MaskedZones = zonesRasterArray\n",
    "#uniqZones = np.unique(MaskedZones)\n",
    "\n",
    "rasterIdxToNames = pandas.read_csv(pathToZonesCategories)\n",
    "## Add the row for the NoDataVal\n",
    "rasterIdxToNames.loc[-1] = [ZoneNoDataVal, \"NoVal\"]\n",
    "rasterIdxToNames.index = rasterIdxToNames.index + 1  # shifting index\n",
    "rasterIdxToNames = rasterIdxToNames.sort_index()\n",
    "\n",
    "#uniqZones.remove(ZoneNoDataVal)\n",
    "\n",
    "##Place holders\n",
    "#for zID in uniqZones:\n",
    "#    allStats[zID] = {}\n",
    "\n",
    "#zone_GeoTrans\n",
    "\n",
    "#Open shapefile\n",
    "#clipPolys = ogr.Open(pathToShapefile)\n",
    "#lyr = clipPolys.GetLayer(0)\n",
    "#clipExt = lyr.GetExtent()\n",
    "\n",
    "#Print feature count\n",
    "#lyr.GetFeatureCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#index = np.argwhere(uniqZones==ZoneNoDataVal)\n",
    "#uniqZones = np.delete(uniqZones, index)\n",
    "#uniqZones = uniqZones.sorted()\n",
    "#uniqZones = np.unique(MaskedZones)\n",
    "\n",
    "#Place holders\n",
    "#for zID in uniqZones:\n",
    "#    allStats[zID] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9999     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12    13    14    15    16    17    18    19    20    21    22    23\n",
      "    24    25    26    27    28    29    30    31    32    33    34    35\n",
      "    36    37    38    39    40    41    42    43    44    45    46    47\n",
      "    48    49    50    51    52    53    54    55    56    57    58    59\n",
      "    60    61    62    63    64    65    66    67    68    69    70    71\n",
      "    72    73    74    75    76    77    78    79    80    81    82    83\n",
      "    84    85    86    87    88    89    90    91    92    93    94    95\n",
      "    96    97    98    99   100   101   102   103   104   105   106   107\n",
      "   108   109   110   111   112   113   114   115   116   117   118   119\n",
      "   120   121   122   123   124   125   126   127   128   129   130   131\n",
      "   132   133   134   135   136   137   138   139   140   141   142   143\n",
      "   144   145   146   147   148   149   150   151   152   153   154   155\n",
      "   156   157   158   159   160   161   162   163   164   165   166   167\n",
      "   168   169   170   171   172   173   174   175   176   177   178   179\n",
      "   180   181   182   183   184   185   186   187   188   189   190   191\n",
      "   192   193   194   195   196   197   198   199   200   201   202   203\n",
      "   204   205   206   207   208   209   210   211   212   213   214   215\n",
      "   216   217   218   219   220   221   222   223   224   225   226   227\n",
      "   228   229   230   231   232   233   234   235   236   237   238   239\n",
      "   240   241   242   243   244   245   246   247   248   249   250   251\n",
      "   252   253   254   255   256   257   258   259   260   261   262   263\n",
      "   264   265   266   267   268   269   270   271   272   273   274   275\n",
      "   276   277   278   279   280   281   282   283   284   285   286   287\n",
      "   288   289   290   291   292   293   294   295   296   297   298   299\n",
      "   300   301   302   303   304   305   306   307   308   309   310   311\n",
      "   312   313   314   315   316   317   318   319   320   321   322   323\n",
      "   324   325   326   327   328   329   330   331   332   333   334   335\n",
      "   336   337   338   339   340   341   342   343   344   345   346   347\n",
      "   348   349   350   351   352   353   354   355   356   357   358   359\n",
      "   360   361   362   363   364   365   366   367   368   369   370   371\n",
      "   372   373   374   375   376   377   378   379   380   381   382   383\n",
      "   384   385   386   387   388   389   390   391   392   393   394   395\n",
      "   396   397   398   399   400   401   402   403   404   405   406   407\n",
      "   408   409   410   411   412   413   414   415   416   417   418   419\n",
      "   420   421   422   423   424   425   426   427   428   429   430   431\n",
      "   432   433   434   435   436   437   438   439   440   441   442   443\n",
      "   444   445   446   447   448   449   450   451   452   453   454   455\n",
      "   456   457   458   459   460   461   462   463   464   465   466   467\n",
      "   468   469   470   471   472   473   474   475   476   477   478   479\n",
      "   480   481   482   483   484   485   486   487   488   489   490   491\n",
      "   492   493   494   495   496   497   498   499   500   501   502   503\n",
      "   504   505   506   507   508   509   510   511   512   513   514   515\n",
      "   516   517   518   519   520   521   522   523   524   525   526   527\n",
      "   528   529   530   531   532   533   534   535   536   537   538   539\n",
      "   540   541   542   543   544   545   546   547   548   549   550   551\n",
      "   552   553   554   555   556   557   558   559   560   561   562   563\n",
      "   564   565   566   567   568   569   570   571   572   573   574   575\n",
      "   576   577   578   579   580   581   582   583   584   585   586   587\n",
      "   588   589   590   591   592   593   594   595   596   597   598   599\n",
      "   600   601   602   603   604   605   606   607   608   609   610   611\n",
      "   612   613   614   615   616   617   618   619   620   621   622   623\n",
      "   624   625   626   627   628   629   630   631   632   633   634   635\n",
      "   636   637   638   639   640   641   642   643   644   645   646   647\n",
      "   648   649   650   651   652   653   654   655   656   657   658   659\n",
      "   660   661   662   663   664   665   666   667   668   669   670   671\n",
      "   672   673   674   675   676   677   678   679   680   681   682]\n"
     ]
    }
   ],
   "source": [
    "print(uniqZones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(str(len(uniqZones)))\n",
    "#MaskedZones = np.ma.masked_where(zonesRasterArray==ZoneNoDataVal, zonesRasterArray)\n",
    "#index = np.argwhere(uniqZones==ZoneNoDataVal)\n",
    "#print(index)\n",
    "#uniqZones = np.delete(uniqZones, index)\n",
    "#print(str(len(uniqZones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reProjectAndReSampleRaster(templateRaster, dataRaster):\n",
    "    dataProj = dataRaster.GetProjection()\n",
    "    dataRef = dataRaster.GetRasterBand(1)\n",
    "    referenceProj = templateRaster.GetProjection()\n",
    "    referenceTrans = templateRaster.GetGeoTransform()\n",
    "    x = templateRaster.RasterXSize\n",
    "    y = templateRaster.RasterYSize\n",
    "    #Keep data type simple for storage space, we know we're dealing with integers here\n",
    "    #Allowing nearest neighbour resampling\n",
    "    output = gdal.GetDriverByName(\"GTiff\").Create(tempRasterPath, x, y, 1, dataRef.DataType)\n",
    "    ###Need a 'No Data Val' that is different to Zero, because that will cause dramas for zero-cover...\n",
    "    #Can't use -9999!, use 240 as it is higher than any valid data value\n",
    "    output.GetRasterBand(1).SetNoDataValue(ourNoData)\n",
    "    output.SetGeoTransform(referenceTrans)\n",
    "    output.SetProjection(referenceProj)\n",
    "    #gdalconst.GRA_Bilinear\n",
    "    gdal.ReprojectImage(dataRaster,output,dataProj,referenceProj,gdalconst.GRA_NearestNeighbour)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processCoverFile(fullFileName):\n",
    "    \n",
    "    fName = os.path.basename(fullFileName)\n",
    "    \n",
    "    beginningIdx = fName.index('_m') + 2\n",
    "    endingIdx = beginningIdx + 12\n",
    "    #print(\"Found at: \" + str(beginningIdx))\n",
    "    #print(\"Found at: \" + fName[beginningIdx:endingIdx])\n",
    "    \n",
    "    searchBit = fName[beginningIdx:endingIdx]\n",
    "    \n",
    "    theStartDate = datetime.date(int(fName[beginningIdx:beginningIdx+4]),int(fName[beginningIdx+4:beginningIdx+6]),1)\n",
    "    \n",
    "    endYear = fName[beginningIdx+6:beginningIdx+10]\n",
    "    endMonth = fName[beginningIdx+10:beginningIdx+12]\n",
    "    \n",
    "    maxDay = calendar.monthrange(int(endYear), int(endMonth))[1]\n",
    "    \n",
    "    theEndDate = datetime.date(int(endYear),int(endMonth),maxDay)\n",
    "    \n",
    "    if (((theStartDate >= requiredStartDate) and (theStartDate <= requiredEndDate)) or ((theEndDate >= requiredStartDate) and (theEndDate <= requiredEndDate))):\n",
    "        #Yep, process this fellow\n",
    "        now = datetime.datetime.now()\n",
    "        print(now.strftime(\"%Y-%m-%d %H:%M\")+ \" Processing cover for period: \" + str(theStartDate) + \" to \" + str(theEndDate))\n",
    "        \n",
    "        alreadyHaveDate = False\n",
    "        for existSDate in foundStartDates:\n",
    "            if existSDate == str(theStartDate):\n",
    "                alreadyHaveDate = True\n",
    "                break\n",
    "            \n",
    "        if alreadyHaveDate == False:\n",
    "            foundStartDates.append(str(theStartDate))\n",
    "        \n",
    "        #open cover raster\n",
    "        print(\"Opening fractional cover: \" + fName)\n",
    "        covRas = gdal.Open(fullFileName)\n",
    "        covRas_GeoTrans = covRas.GetGeoTransform()\n",
    "        \n",
    "        if (covRas_GeoTrans != zone_GeoTrans):\n",
    "            #Need to reproject/resample\n",
    "            print(\"Cover raster resolution info didn't match template, attempted a resample\")\n",
    "            reProjectAndReSampleRaster(zoneRas, covRas)\n",
    "            #Load resampled raster from temp area\n",
    "            covRas = gdal.Open(tempRasterPath)\n",
    "            covRas_GeoTrans = covRas.GetGeoTransform()\n",
    "            #Do we check????\n",
    "            if (covRas_GeoTrans == zone_GeoTrans):\n",
    "                print(\"Cover raster resolution now matches\")\n",
    "            \n",
    "        \n",
    "        #find & open patch raster\n",
    "        patchFileName = None\n",
    "        for patchFile in availPatchRasters:\n",
    "            if(os.path.basename(patchFile).find(searchBit) != -1):\n",
    "                patchFileName = patchFile\n",
    "                break\n",
    "        \n",
    "        \n",
    "        print(\"Opening patch data: \" + os.path.basename(patchFileName))\n",
    "        patchRas = gdal.Open(patchFileName)\n",
    "        patchRas_GeoTrans = patchRas.GetGeoTransform()\n",
    "        \n",
    "        if (patchRas_GeoTrans != zone_GeoTrans):\n",
    "            print(\"Patch raster resolution info didn't match template, attempted a resample\")\n",
    "            reProjectAndReSampleRaster(zoneRas, patchRas)\n",
    "            #Load resampled raster from temp area\n",
    "            patchRas = gdal.Open(tempRasterPath)\n",
    "            patchRas_GeoTrans = patchRas.GetGeoTransform()\n",
    "            if (patchRas_GeoTrans == zone_GeoTrans):\n",
    "                print(\"Patch raster resolution now matches\")\n",
    "        \n",
    "        \n",
    "        #Should be no need to do clipping now, re-sampling would've done it?\n",
    "        \n",
    "        #newRasterInfo = shapeExtent_To_Raster_Box(clipExt, origRas_GeoTrans)\n",
    "        #patchRasterInfo = shapeExtent_To_Raster_Box(clipExt, origPatchRas.GetGeoTransform())\n",
    "        \n",
    "        print(\"Working...\")\n",
    "        sourceRastArray = covRas.GetRasterBand(1).ReadAsArray()\n",
    "        patchRastArray = patchRas.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "        ##clip = rast[ulY:lrY, ulX:lrX]\n",
    "        #clipSourceRast = sourceRast[newRasterInfo[8]:newRasterInfo[9],newRasterInfo[6]:newRasterInfo[7]]\n",
    "        #clipPatchRast = patchRast[patchRasterInfo[8]:patchRasterInfo[9],patchRasterInfo[6]:patchRasterInfo[7]]\n",
    "\n",
    "\n",
    "        ##Introduce mask of NoDatas\n",
    "        ##This will include ocean as well as gaps\n",
    "        ##clipSourceRast = numpy.ma.masked_values(clipSourceRast, origRas.GetRasterBand(1).GetNoDataValue())\n",
    "        ##clipPatchRast = numpy.ma.masked_values(clipPatchRast, origPatchRas.GetRasterBand(1).GetNoDataValue())\n",
    "        #clipSourceRast = numpy.ma.masked_where((clipSourceRast < 100) | (clipSourceRast > 200) | (clipSourceRast ==  origRas.GetRasterBand(1).GetNoDataValue()), clipSourceRast)\n",
    "        #clipPatchRast = numpy.ma.masked_where((clipPatchRast < 100) | (clipPatchRast > 200) | (clipPatchRast == origPatchRas.GetRasterBand(1).GetNoDataValue()), clipPatchRast)\n",
    "        clipSourceRast = np.ma.masked_where((sourceRastArray < 100) | (sourceRastArray > 200) | (sourceRastArray ==  covRas.GetRasterBand(1).GetNoDataValue()), sourceRastArray)\n",
    "        clipPatchRast = np.ma.masked_where((patchRastArray < 100) | (patchRastArray > 200) | (patchRastArray == patchRas.GetRasterBand(1).GetNoDataValue()), patchRastArray)\n",
    "\n",
    "        \n",
    "        #Free up some memory\n",
    "        sourceRastArray = None\n",
    "        patchRastArray = None\n",
    "        \n",
    "        clipPatchRast = np.ma.masked_values(clipPatchRast, patchRas.GetRasterBand(1).GetNoDataValue())\n",
    "        \n",
    "        insertedPatch = np.ma.masked_values(clipSourceRast.filled(clipPatchRast), patchRas.GetRasterBand(1).GetNoDataValue())\n",
    "        \n",
    "        #Need to change data type of array so that we can go above values of 255\n",
    "        patchedMask = np.array(insertedPatch, dtype='f')\n",
    "        patchedMask = np.ma.masked_values(patchedMask, patchRas.GetRasterBand(1).GetNoDataValue())\n",
    "        \n",
    "        ###Need a 'No Data Val' that is different to Zero, because that will cause dramas for zero-cover...\n",
    "        #Can't use -9999!, go 240\n",
    "        patchedMask = patchedMask.filled(ourNoData)\n",
    "        patchedMask = np.ma.masked_values(patchedMask, ourNoData)\n",
    "        \n",
    "        #Important! Use 200.0, not '200', to ensure we retain 'float' data type\n",
    "        gCov = 200.0-patchedMask\n",
    "        \n",
    "        visPatched = 0.00925 * np.power(gCov, 2)\n",
    "\n",
    "        ##This essential to allow us insert NoDatas in final product... again....\n",
    "        visPatched = visPatched.filled(ourNoData)\n",
    "        visPatched = np.ma.masked_values(visPatched, ourNoData)\n",
    "        \n",
    "        #img_masked = np.where(visPatched, visPatched, np.nan)\n",
    "        \n",
    "        ####Now we can do zonal stats......\n",
    "        ##Just use numpy arrays\n",
    "        print(\"Doing zonal stats on \" + str(len(uniqZones)) + \" unique zones\")\n",
    "        #outStats = scipy.ndimage.measurements.mean(visPatched, labels=MaskedZones, index=uniqZones)\n",
    "        #outStats = scipy.ndimage.measurements.mean(visPatched.filled(np.nan), labels=MaskedZones, index=uniqZones)\n",
    "        \n",
    "        #This uses the Bincount method (detailed in comments below), but in a module we can use from other places\n",
    "        outStats = zonalMeanByBincount.zonalMeanByBincount(zonesRasterArray, visPatched)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #Try our own bincount, without Module\n",
    "#         unique_labels, new_labels = np.unique(zonesRasterArray, return_inverse=True)\n",
    "\n",
    "#         #print(\"Labs:\")\n",
    "#         #print(unique_labels)\n",
    "        \n",
    "#         ##new_labels = new_labels.filled(ourNoData)\n",
    "#         #new_labels = np.ma.masked_values(new_labels, ourNoData)\n",
    "#         ##vpRav = visPatched.ravel()\n",
    "#         ##vpRav.filled(ourNoData)\n",
    "#         ##new_labels = np.ma.masked_where(vpRav != ourNoData, new_labels)\n",
    "#         #counts = np.bincount(new_labels)\n",
    "#         newPatch = visPatched.ravel()\n",
    "#         newPatch = newPatch.filled(np.nan)\n",
    "#         keep = ~np.isnan(newPatch)\n",
    "#         #newPatch = np.ma.masked_values(newPatch, 0.0)\n",
    "        \n",
    "#         #print(\"Is masked???: \" + str(np.ma.is_masked(newPatch)))\n",
    "        \n",
    "#         counts = np.bincount(new_labels[keep])\n",
    "        \n",
    "#         #sums = np.bincount(new_labels, weights=visPatched.ravel())\n",
    "#         sums = np.bincount(new_labels[keep], weights=newPatch[keep])\n",
    "        \n",
    "#         outStats = sums/np.asanyarray(counts).astype(np.float)\n",
    "        \n",
    "        \n",
    "        ###This method similar to what zonal stats from web examples does, but its slow\n",
    "        #for zID in uniqZones:\n",
    "        #    if zID == ZoneNoDataVal:\n",
    "        #        print(\"Ignoring value: \" + str(zID))\n",
    "        #        continue\n",
    "                \n",
    "            \n",
    "        #    masked = np.ma.masked_where(np.not_equal(zonesRasterArray, zID), visPatched)\n",
    "        #    allStats[zID][str(theStartDate)] = float(masked.mean())\n",
    "        #    print(\"Added to catchID:\" + str(zID) + \" meanCover: \" + str(allStats[zID][str(theStartDate)]))\n",
    "        \n",
    "        \n",
    "        ###This looping option even slower than repeated masking\n",
    "        #outStatsCount = {}\n",
    "        #outStatsSum = {}\n",
    "        \n",
    "        #for unZID in uniqZones:\n",
    "        #    outStatsCount[unZID] = 0\n",
    "        #    outStatsSum[unZID] = 0\n",
    "        \n",
    "        #i = 0\n",
    "        #while i < zoneRas.RasterYSize:\n",
    "            \n",
    "        #    j = 0\n",
    "            \n",
    "        #    while j < zoneRas.RasterXSize:\n",
    "                \n",
    "        #        #if MaskedZones[i,j] == 'masked':\n",
    "        #        if zonesRasterArray[i,i] == ZoneNoDataVal:\n",
    "        #            continue\n",
    "                \n",
    "        #        if visPatched[i,j] == ourNoData:\n",
    "        #            continue\n",
    "                \n",
    "                \n",
    "        #        outStatsCount[MaskedZones[i,j]] += 1\n",
    "        #        outStatsSum[MaskedZones[i,j]] += visPatched[i,j]\n",
    "        \n",
    "        \n",
    "        #outStats = []\n",
    "        \n",
    "        #for unZID in uniqZones:\n",
    "        #    if outStatsCount[unZID] == 0:\n",
    "        #        outStats.append('NA')\n",
    "        #    else:\n",
    "        #        outStats.append(outStatsSum[unZID]/outStatsCount[unZID])\n",
    "            \n",
    "\n",
    "        allStats[str(theStartDate)] = outStats\n",
    "\n",
    "        #print(outStats)\n",
    "\n",
    "\n",
    "        #Cfactor....\n",
    "        #cFactor = numpy.exp(-0.799 - (0.0474 * visPatched) + (0.000449 * numpy.power(visPatched, 2)) - (0.0000052 * numpy.power(visPatched, 3)))\n",
    "        #cFactor = numpy.ma.masked_values(cFactor, ourNoData)\n",
    "\n",
    "        if (saveCover):\n",
    "            ###\n",
    "            outputFile = os.path.join(outputDir, \"cov_\" + searchBit + \".tif\")\n",
    "            \n",
    "            print(\"Saving: \" + outputFile)\n",
    "\n",
    "            #Integer will be fine for cover bands\n",
    "            #GDT_Byte is 8 bit unsigned (apparently)\n",
    "            \n",
    "            #outDS = gdal.GetDriverByName(\"GTiff\").Create(outputFile, newRasterInfo[4], newRasterInfo[5], 1, gdal.GDT_Byte)\n",
    "            #outDS.SetGeoTransform((newRasterInfo[0], newRasterInfo[2], 0, newRasterInfo[1], 0, newRasterInfo[3]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            outDS = gdal.GetDriverByName(\"GTiff\").Create(outputFile, zoneRas.RasterXSize, zoneRas.RasterYSize, 1, gdal.GDT_Byte)\n",
    "            outDS.SetGeoTransform((zone_GeoTrans[0], zone_GeoTrans[1], zone_GeoTrans[2], zone_GeoTrans[3], zone_GeoTrans[4], zone_GeoTrans[5]))\n",
    "            \n",
    "            #outDS.SetProjection(origRas.GetProjection())\n",
    "            outBand = outDS.GetRasterBand(1)\n",
    "\n",
    "            # write the data\n",
    "            outBand.WriteArray(visPatched)\n",
    "\n",
    "            # flush data to disk, set the NoData value and calculate stats\n",
    "            outBand.FlushCache()\n",
    "            outBand.SetNoDataValue(ourNoData)\n",
    "            outDS.SetProjection(zoneRas.GetProjection())\n",
    "            \n",
    "            del outDS, outBand\n",
    "\n",
    "        #if (saveCFact):\n",
    "        #    ##\n",
    "        #    outputCFactFile = os.path.join(outputDir, \"cf_\" + searchBit + \".tif\")\n",
    "        #    \n",
    "        #    print(\"Saving: \" + outputCFactFile)\n",
    "        #    \n",
    "        #    outDSCFact = gdal.GetDriverByName(\"GTiff\").Create(outputCFactFile, newRasterInfo[4], newRasterInfo[5], 1, gdal.GDT_Float32)\n",
    "        #    outDSCFact.SetGeoTransform((newRasterInfo[0], newRasterInfo[2], 0, newRasterInfo[1], 0, newRasterInfo[3]))\n",
    "        #\n",
    "        #    outDSCFact.SetProjection(origRas.GetProjection())\n",
    "        #    outBandCFact = outDSCFact.GetRasterBand(1)\n",
    "        #\n",
    "        #    outBandCFact.WriteArray(cFactor)\n",
    "        #    outBandCFact.FlushCache()\n",
    "        #    outBandCFact.SetNoDataValue(ourNoData)\n",
    "        #\n",
    "        #    # georeference the image and set the projection (ROB: don't do GeoTransform, we've already done that)\n",
    "        #    ##outDs.SetGeoTransform(inDs.GetGeoTransform())\n",
    "        #    outDSCFact.SetProjection(origRas.GetProjection())\n",
    "\n",
    "        #    #Without this 'del', the output file doesn't get populated with values???\n",
    "        #    del outDSCFact, outBandCFact\n",
    "\n",
    "            \n",
    "            \n",
    "        clipPatchRast = None\n",
    "        clipSourceRast = None\n",
    "        patchedMask = None\n",
    "        gCov = None\n",
    "        visPatched = None\n",
    "        cFactor = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-04 12:38 Processing cover for period: 1989-09-01 to 1989-11-30\n",
      "Opening fractional cover: lztmre_qld_m198909198911_dixa2.tif\n",
      "Cover raster resolution info didn't match template, attempted a resample\n",
      "Cover raster resolution now matches\n",
      "Opening patch data: lztmre_rreef_m198909198911_dj4a2.tif\n",
      "Patch raster resolution info didn't match template, attempted a resample\n",
      "Patch raster resolution now matches\n",
      "Working...\n",
      "Doing zonal stats on 683 unique zones\n",
      "2018-09-04 12:38 Processing cover for period: 1989-12-01 to 1990-02-28\n",
      "Opening fractional cover: lztmre_qld_m198912199002_dixa2.tif\n",
      "Cover raster resolution info didn't match template, attempted a resample\n",
      "Cover raster resolution now matches\n",
      "Opening patch data: lztmre_rreef_m198912199002_dj4a2.tif\n",
      "Patch raster resolution info didn't match template, attempted a resample\n",
      "Patch raster resolution now matches\n",
      "Working...\n",
      "Doing zonal stats on 683 unique zones\n",
      "2018-09-04 12:39 Processing cover for period: 1990-03-01 to 1990-05-31\n",
      "Opening fractional cover: lztmre_qld_m199003199005_dixa2.tif\n",
      "Cover raster resolution info didn't match template, attempted a resample\n",
      "Cover raster resolution now matches\n",
      "Opening patch data: lztmre_rreef_m199003199005_dj4a2.tif\n",
      "Patch raster resolution info didn't match template, attempted a resample\n",
      "Patch raster resolution now matches\n",
      "Working...\n",
      "Doing zonal stats on 683 unique zones\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for theFile in availCoverRasters:\n",
    "    processCoverFile(theFile)\n",
    "\n",
    "print(\"All done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1989-09-01', '1989-12-01', '1990-03-01']\n"
     ]
    }
   ],
   "source": [
    "#Now to get at the data...\n",
    "print(foundStartDates)\n",
    "#rasterIdxToNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989-09-01 Length: 683\n",
      "1989-12-01 Length: 683\n",
      "1990-03-01 Length: 683\n"
     ]
    }
   ],
   "source": [
    "#dFrame = pandas.DataFrame()\n",
    "#dFrame['zones'] = uniqZones\n",
    "\n",
    "#rasterIdxToNames.sort_values(by=['Ras_ID'])\n",
    "\n",
    "\n",
    "#dFrame\n",
    "\n",
    "#sTd = foundStartDates.sort()\n",
    "\n",
    "\n",
    "for eachSDate in foundStartDates:\n",
    "    print(str(eachSDate) + \" Length: \" + str(len(allStats[eachSDate])))\n",
    "    \n",
    "    if len(allStats[eachSDate]) == 683:\n",
    "        rasterIdxToNames[eachSDate] = allStats[eachSDate]\n",
    "    \n",
    "\n",
    "\n",
    "#for unZID in uniqZones:\n",
    "#    for eachSDate in sTd:\n",
    "#        dFrame[str(unZID)] = allStats[zID][eachSDate]\n",
    "\n",
    "#for eachSDate in foundStartDates.sorted():\n",
    "#    for unZID in uniqZones:\n",
    "#        dFrame[str(unZID)] = allStats[zID][eachSDate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rasterIdxToNames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported at: 2018-09-04 12:39\n"
     ]
    }
   ],
   "source": [
    "rasterIdxToNames.to_csv(outputCSV, index=False)\n",
    "now = datetime.datetime.now()\n",
    "print(\"File exported at: \" + now.strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
