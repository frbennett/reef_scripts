{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Robs Seasonal USLE stabulator\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#import libarchive\n",
    "#import tempfile\n",
    "import os\n",
    "##from functools import reduce\n",
    "#import datetime\n",
    "\n",
    "sepChar = '$'\n",
    "\n",
    "subDIRs = ['Cfact', 'KLSC', 'KLSC_Fines']\n",
    "#subDIRs = ['KLSC', 'KLSC_Fines']\n",
    "\n",
    "#topPath = r'P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\DummyInputs'\n",
    "topPath = r'P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\TSInputs'\n",
    "outputPath = r'P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations'\n",
    "\n",
    "existColStr = 'Date'\n",
    "dateColStr = 'SeasonStart'\n",
    "\n",
    "reqDateStrings = ['1/06/1986', '1/09/1986', '1/12/1986', '1/03/1987', '1/06/1987', '1/09/1987', '1/12/1987', '1/03/1988',\n",
    "                  '1/06/1988', '1/09/1988', '1/12/1988', '1/03/1989', '1/06/1989', '1/09/1989', '1/12/1989', '1/03/1990',\n",
    "                  '1/06/1990', '1/09/1990', '1/12/1990', '1/03/1991', '1/06/1991', '1/09/1991', '1/12/1991', '1/03/1992',\n",
    "                  '1/06/1992', '1/09/1992', '1/12/1992', '1/03/1993', '1/06/1993', '1/09/1993', '1/12/1993', '1/03/1994',\n",
    "                  '1/06/1994', '1/09/1994', '1/12/1994', '1/03/1995', '1/06/1995', '1/09/1995', '1/12/1995', '1/03/1996',\n",
    "                  '1/06/1996', '1/09/1996', '1/12/1996', '1/03/1997', '1/06/1997', '1/09/1997', '1/12/1997', '1/03/1998',\n",
    "                  '1/06/1998', '1/09/1998', '1/12/1998', '1/03/1999', '1/06/1999', '1/09/1999', '1/12/1999', '1/03/2000',\n",
    "                  '1/06/2000', '1/09/2000', '1/12/2000', '1/03/2001', '1/06/2001', '1/09/2001', '1/12/2001', '1/03/2002',\n",
    "                  '1/06/2002', '1/09/2002', '1/12/2002', '1/03/2003', '1/06/2003', '1/09/2003', '1/12/2003', '1/03/2004',\n",
    "                  '1/06/2004', '1/09/2004', '1/12/2004', '1/03/2005', '1/06/2005', '1/09/2005', '1/12/2005', '1/03/2006',\n",
    "                  '1/06/2006', '1/09/2006', '1/12/2006', '1/03/2007', '1/06/2007', '1/09/2007', '1/12/2007', '1/03/2008',\n",
    "                  '1/06/2008', '1/09/2008', '1/12/2008', '1/03/2009', '1/06/2009', '1/09/2009', '1/12/2009', '1/03/2010',\n",
    "                  '1/06/2010', '1/09/2010', '1/12/2010', '1/03/2011', '1/06/2011', '1/09/2011', '1/12/2011', '1/03/2012',\n",
    "                  '1/06/2012', '1/09/2012', '1/12/2012', '1/03/2013', '1/06/2013', '1/09/2013', '1/12/2013', '1/03/2014', '1/06/2014']\n",
    "\n",
    "\n",
    "resultsDict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made dir: P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "    print(\"Made dir: \" + outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing dir: Cfact\n",
      "Doing dir: KLSC\n",
      "Doing dir: KLSC_Fines\n",
      "Everything Collected\n"
     ]
    }
   ],
   "source": [
    "resultsDict = {}\n",
    "for subD in subDIRs:\n",
    "    \n",
    "    thisDir = os.path.join(topPath, subD)\n",
    "    \n",
    "    print(\"Doing dir: \" + subD)\n",
    "    \n",
    "    if os.path.exists(thisDir):\n",
    "        \n",
    "        resultsDict[subD] = {}\n",
    "        \n",
    "        for fName in os.listdir(thisDir):\n",
    "            \n",
    "            fullFileName = os.path.join(thisDir, fName)\n",
    "            \n",
    "            #print(\"f name: \" + fName)\n",
    "            \n",
    "            #print(\"Full name: \" + fullFileName)\n",
    "\n",
    "            components = fName.split(sepChar)\n",
    "            \n",
    "            catchName = components[0]\n",
    "            fuName = components[1]\n",
    "            \n",
    "            if not fuName in resultsDict[subD]:\n",
    "                #print(\"In here\")\n",
    "                resultsDict[subD][fuName] = pd.DataFrame({dateColStr:reqDateStrings})\n",
    "                \n",
    "            \n",
    "            #read in the CSV\n",
    "            dataDF = pd.read_csv(fullFileName, error_bad_lines=False)\n",
    "            \n",
    "            #Filter dates\n",
    "            dataDF = dataDF.loc[dataDF[existColStr].isin(reqDateStrings)]\n",
    "            dataDF.columns = [dateColStr, catchName]\n",
    "            \n",
    "            #print(dataDF)\n",
    "            \n",
    "            combinedDF = pd.merge(resultsDict[subD][fuName], dataDF, how='left', left_on=[dateColStr], right_on = [dateColStr])\n",
    "            resultsDict[subD][fuName] = combinedDF\n",
    "            \n",
    "            #Going to go without merging/joining, rely on everything being in the right order?\n",
    "            #resultsDict[subD][fuName][catchName] = dataDF[catchName]\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Everything Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resultsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\Cfact$Conservation.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\Cfact$Grazing Forested.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\Cfact$Grazing Open.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\Cfact$Forestry.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC$Conservation.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC$Grazing Forested.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC$Grazing Open.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC$Forestry.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC_Fines$Conservation.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC_Fines$Grazing Forested.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC_Fines$Grazing Open.csv\n",
      "Saved:P:\\projects\\RC9_ResultsSets\\ArchiveStuff\\BU\\USLE\\Tabulations\\KLSC_Fines$Forestry.csv\n",
      "Saving Done\n"
     ]
    }
   ],
   "source": [
    "#now write the results\n",
    "\n",
    "for theVar in resultsDict:\n",
    "    #print(\"Doing saving on: \" + theVar)\n",
    "    for theFU in resultsDict[theVar]:\n",
    "        #print(\"Doing saving on: \" + theFU)\n",
    "        theOutFileName = os.path.join(outputPath, theVar + sepChar + theFU + \".csv\")\n",
    "        \n",
    "        resultsDict[theVar][theFU].to_csv(theOutFileName, index=False)\n",
    "        print(\"Saved:\" + theOutFileName)\n",
    "\n",
    "print(\"Saving Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
